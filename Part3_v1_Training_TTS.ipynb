{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part3_v1_Training TTS",
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hantswilliams/voiceCloneTts/blob/main/Part3_v1_Training_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTtY_ZTjmSAp"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBSInou8kz7X"
      },
      "source": [
        "#### Install Repo to Google Drive\n",
        "\n",
        "Colab is a little funky. I’ve found the best way to do this is to install the repo directly into your Google Drive folder. This will save the training if it crashes. \n",
        "\n",
        "First, mount your Drive to the Colab notebook: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umI5wmJWINtn",
        "outputId": "0a6fbbbf-b2cb-4b7d-afcd-8df2164615b4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zr2B0x3k9XH"
      },
      "source": [
        "#### Installing Libraries\n",
        "Next, run the cell below. If you’re already installed the repo, it will skip the installation process and change into the repo’s directory. If you haven’t installed it, it will install all the libraries necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKLe9qLoJLhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53dfd426-fc7c-4fe4-d8f0-5aff0e83aa99"
      },
      "source": [
        "import os\n",
        "if os.path.isdir(\"/content/drive/MyDrive/VoiceCloning\"):\n",
        "    %cd \"/content/drive/My Drive/VoiceCloning/TTS\"\n",
        "    !pip install -e .[all]\n",
        "    !pip install --upgrade numpy\n",
        "    %cd ..\n",
        "    \n",
        "else:\n",
        "    #installs all needed files and libraries\n",
        "    %cd \"/content/drive/My Drive/\"\n",
        "    !mkdir VoiceCloning\n",
        "    %cd VoiceCloning\n",
        "    !git clone https://github.com/coqui-ai/TTS\n",
        "    !mkdir datasets\n",
        "    !mkdir log \n",
        "    !mkdir configs\n",
        "    !mkdir models\n",
        "    !mkdir output\n",
        "    !mkdir WadaSNR\n",
        "\n",
        "    !gdown https://drive.google.com/uc?id=1BksOJ-I10F0Itt2WM6kKrNmKYgOVSNSl -O /content/drive/MyDrive/VoiceCloning/models/vits_model.tar #change this link to change model to train off of (for instance training off of a different language)\n",
        "    !gdown https://drive.google.com/uc?id=1gqogUxwBeuzL0qxJJBNArYzga79P-GDP -O /content/drive/MyDrive/VoiceCloning/TTS/TTS/tts/datasets/formatters.py\n",
        "    !gdown https://drive.google.com/uc?id=180cb7NPgbcqwqCTdZv_2nc4JsQaC0Wcl -O /content/drive/MyDrive/VoiceCloning/configs/generic_config.json\n",
        "    !gdown https://drive.google.com/uc?id=1BFY3Q8HInytSfOG3i3lsIAR3XdVcgBc1 -O /content/drive/MyDrive/VoiceCloning/configs/train_vits.py #\n",
        "    %cd TTS \n",
        "    !pip install .\n",
        "    !pip install --upgrade numpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/VoiceCloning/TTS\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/drive/My%20Drive/VoiceCloning/TTS\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (4.64.0)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (1.12.0+cu113)\n",
            "Collecting umap-learn==0.5.1\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (0.42.1)\n",
            "Collecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (0.12.0+cu113)\n",
            "Collecting librosa==0.8.0\n",
            "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 67.0 MB/s \n",
            "\u001b[?25hCollecting cython==0.29.28\n",
            "  Using cached Cython-0.29.28-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (3.13)\n",
            "Collecting trainer\n",
            "  Downloading trainer-0.0.13-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (0.10.3.post1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (1.1.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (1.3.5)\n",
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.47.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 48.8 MB/s \n",
            "\u001b[?25hCollecting inflect==5.6.0\n",
            "  Downloading inflect-5.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from TTS==0.7.1) (1.7.3)\n",
            "Collecting coqpit>=0.0.16\n",
            "  Downloading coqpit-0.0.16-py3-none-any.whl (13 kB)\n",
            "Collecting numba==0.55.1\n",
            "  Downloading numba-0.55.1-1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting fsspec>=2021.04.0\n",
            "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 67.1 MB/s \n",
            "\u001b[?25hCollecting mecab-python3==1.0.5\n",
            "  Downloading mecab_python3-1.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (574 kB)\n",
            "\u001b[K     |████████████████████████████████| 574 kB 74.2 MB/s \n",
            "\u001b[?25hCollecting unidic-lite==1.0.8\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting pyworld==0.2.10\n",
            "  Downloading pyworld-0.2.10.tar.gz (73 kB)\n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting black\n",
            "  Downloading black-22.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 50.8 MB/s \n",
            "\u001b[?25hCollecting coverage\n",
            "  Downloading coverage-6.4.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting pylint==2.10.2\n",
            "  Downloading pylint-2.10.2-py3-none-any.whl (392 kB)\n",
            "\u001b[K     |████████████████████████████████| 392 kB 67.6 MB/s \n",
            "\u001b[?25hCollecting nose2\n",
            "  Downloading nose2-0.12.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 71.8 MB/s \n",
            "\u001b[?25hCollecting isort\n",
            "  Downloading isort-5.10.1-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 66.8 MB/s \n",
            "\u001b[?25hCollecting bokeh==1.4.0\n",
            "  Downloading bokeh-1.4.0.tar.gz (32.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.4 MB 88.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->TTS==0.7.1) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->TTS==0.7.1) (2.8.2)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->TTS==0.7.1) (2.11.3)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->TTS==0.7.1) (7.1.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->TTS==0.7.1) (21.3)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.7/dist-packages (from bokeh==1.4.0->TTS==0.7.1) (5.1.1)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS==0.7.1) (2.10.3)\n",
            "Collecting dateparser~=1.1.0\n",
            "  Downloading dateparser-1.1.1-py2.py3-none-any.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 69.5 MB/s \n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.9 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_en~=2.0.0\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2 MB 32.0 MB/s \n",
            "\u001b[?25hCollecting jsonlines~=1.2.0\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS==0.7.1) (2.6.3)\n",
            "Collecting num2words<1.0.0,>=0.5.10\n",
            "  Downloading num2words-0.5.11-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7\n",
            "  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 72.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS==0.7.1) (5.9.0)\n",
            "Collecting gruut_lang_ru~=2.0.0\n",
            "  Downloading gruut_lang_ru-2.0.0.tar.gz (35.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0 MB 477 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_cs~=2.0.0\n",
            "  Downloading gruut_lang_cs-2.0.0.tar.gz (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 26.4 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_fr~=2.0.0\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 24.3 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_es~=2.0.0\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.4 MB 161 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_sv~=2.0.0\n",
            "  Downloading gruut_lang_sv-2.0.0.tar.gz (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_pt~=2.0.0\n",
            "  Downloading gruut_lang_pt-2.0.0.tar.gz (5.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.0 MB 55.3 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_it~=2.0.0\n",
            "  Downloading gruut_lang_it-2.0.0.tar.gz (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 53.9 MB/s \n",
            "\u001b[?25hCollecting gruut_lang_de~=2.0.0\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.1 MB 551 kB/s \n",
            "\u001b[?25hCollecting gruut_lang_nl~=2.0.0\n",
            "  Downloading gruut_lang_nl-2.0.2.tar.gz (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 21.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS==0.7.1) (2.1.9)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS==0.7.1) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS==0.7.1) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS==0.7.1) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS==0.7.1) (0.3.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS==0.7.1) (1.6.0)\n",
            "Collecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 4.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.55.1->TTS==0.7.1) (57.4.0)\n",
            "Requirement already satisfied: toml>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pylint==2.10.2->TTS==0.7.1) (0.10.2)\n",
            "Collecting astroid<2.8,>=2.7.2\n",
            "  Downloading astroid-2.7.3-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.7.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 63.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from astroid<2.8,>=2.7.2->pylint==2.10.2->TTS==0.7.1) (4.1.1)\n",
            "Collecting wrapt<1.13,>=1.11\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting lazy-object-proxy>=1.4.0\n",
            "  Downloading lazy_object_proxy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting typed-ast<1.5,>=1.4.0\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from Babel<3.0.0,>=2.8.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS==0.7.1) (2022.1)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser~=1.1.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS==0.7.1) (1.5.1)\n",
            "Collecting regex!=2019.02.19,!=2021.8.27,<2022.3.15\n",
            "  Downloading regex-2022.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 65.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh==1.4.0->TTS==0.7.1) (2.0.1)\n",
            "Collecting docopt>=0.6.2\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh==1.4.0->TTS==0.7.1) (3.0.9)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS==0.7.1) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS==0.7.1) (1.4.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS==0.7.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS==0.7.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS==0.7.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS==0.7.1) (2022.6.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->TTS==0.7.1) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->TTS==0.7.1) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->TTS==0.7.1) (2.21)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black->TTS==0.7.1) (2.0.1)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black->TTS==0.7.1) (4.12.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->TTS==0.7.1) (1.1.0)\n",
            "Collecting flask\n",
            "  Downloading Flask-2.2.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.7 MB/s \n",
            "\u001b[?25hCollecting Jinja2>=2.7\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 74.8 MB/s \n",
            "\u001b[?25hCollecting Werkzeug>=2.2.0\n",
            "  Downloading Werkzeug-2.2.1-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black->TTS==0.7.1) (3.8.1)\n",
            "Collecting MarkupSafe>=0.23\n",
            "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->TTS==0.7.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->TTS==0.7.1) (1.4.4)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from trainer->TTS==0.7.1) (3.17.3)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 59.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: bokeh, gruut, librosa, pyworld, umap-learn, unidic-lite, gruut-ipa, gruut-lang-cs, gruut-lang-de, gruut-lang-en, gruut-lang-es, gruut-lang-fr, gruut-lang-it, gruut-lang-nl, gruut-lang-pt, gruut-lang-ru, gruut-lang-sv, docopt, pynndescent, wrapt\n",
            "  Building wheel for bokeh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bokeh: filename=bokeh-1.4.0-py3-none-any.whl size=23689209 sha256=d459bdeed62e18c26a48612a05e20c4c11248bdba6fb74ac0a911f87ee3b540a\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/8c/d1/6b8e1f57e542671673cb3d2faee1a9eccb36be2c08a3915498\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75820 sha256=577f5cc57a21d8c3a5b5eecd37acac9fb475746382c30a73550a9c5aa0959f9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/6a/ef/c07b4563108f071b917e6f9cda1052da696906a0ed2357dcfb\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-py3-none-any.whl size=201396 sha256=658df884d938ec60fba282acabfad1447195e65949b315005cf0b851aa57e365\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/1e/aa/d91797ae7e1ce11853ee100bee9d1781ae9d750e7458c95afb\n",
            "  Building wheel for pyworld (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.2.10-cp37-cp37m-linux_x86_64.whl size=611741 sha256=444c74bf6d3a47ca7bf9f2844ec1c727fcb49fbe64481101a3609add5bad3268\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/6b/a1/ef59ea6908d1aa757f54df9c9143c7e1a22686ab3bf56742f5\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76565 sha256=42e5a81a70b78e244b3771a0999fcec71f12e12440ac193bebb52fa96771c898\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658836 sha256=49bf3a057c2cfdbe50a351d1d44e0566859d85f812e0fced336b66c27b3a11b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/69/b1/112140b599f2b13f609d485a99e357ba68df194d2079c5b1a2\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104895 sha256=cbc1e26b0d3f000c6da26d55df6a7376a3f4dcb129a99a0024dd4803a90e395a\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/71/a1/5c393a68f798dfaea6c4f09e9a13b52cfedd4765db6a18400d\n",
            "  Building wheel for gruut-lang-cs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-cs: filename=gruut_lang_cs-2.0.0-py3-none-any.whl size=7046389 sha256=1eb89a1984356a4339f473f57509ec9ff203ad72f2c225bf7537ddbede697f5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/6b/75/354899a9146b15b09c58c9d41ba734217ce6fc3564b23429da\n",
            "  Building wheel for gruut-lang-de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498200 sha256=2b90fef58c29914dc69ef7555873c0c63660d2cdf212997b9fb754a934211fee\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/e2/2f/fda506cfd22e4bd7435fb38ecf7760f9be1f2d10ab69933b4c\n",
            "  Building wheel for gruut-lang-en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297197 sha256=6fc2a0ace32fd8cdcc70488f74ee768a4094603d6fdccc3cea9895abbb42a6b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/82/a1/88bb90a6ee9896acfa37d9c2bc3dd56dee0b6c91ae13b0f0bf\n",
            "  Building wheel for gruut-lang-es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173815 sha256=738586140317f7b9ab4d158a2e94ceb5419277ac1a82e37b3eedc6dae9b9e415\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/0c/5d/a5dacfeeb7482db19f954fe99e46879629711efb0e5263f1d1\n",
            "  Building wheel for gruut-lang-fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968789 sha256=cdf272a8053cf9add84deef717508f38fb7d9c6f4f9d5686308e4be306511a0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/3e/4a/5f85990f912315dcfbf58b231d3c0880d02bcbf9e139e6b7ae\n",
            "  Building wheel for gruut-lang-it (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-it: filename=gruut_lang_it-2.0.0-py3-none-any.whl size=2961848 sha256=aeb002edd98f7afdbf98b2dc00826c8bebb0781c152a9944fc4d164392537915\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/4f/83/d46fec44ed3ea7cea8941549972daa30dd55213110b34aa168\n",
            "  Building wheel for gruut-lang-nl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-nl: filename=gruut_lang_nl-2.0.2-py3-none-any.whl size=8589106 sha256=f591a5d866cfdb75e34f46713c415827b4e297ce09fa3b1d46bb37e29838d972\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/eb/6e/b4032f17268a19659e1f6682034d74a513f44a1de0877d94d0\n",
            "  Building wheel for gruut-lang-pt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-pt: filename=gruut_lang_pt-2.0.0-py3-none-any.whl size=5033212 sha256=82fc8609f92af876cc13dbad4261520115c0fb5dc20154dbe284a409ef686025\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/6f/a7/65977a42f8bcb4b86ab078622c0b5e0a6c51f16717386435a7\n",
            "  Building wheel for gruut-lang-ru (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-ru: filename=gruut_lang_ru-2.0.0-py3-none-any.whl size=35301045 sha256=54a72d489782993c798400df2ee20f0b10e75387f480e2e330837708ab4194be\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/a2/f7/2c70e405a17ffd53a2773b6a10c8376e0bda1b615ddaa1a40b\n",
            "  Building wheel for gruut-lang-sv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-lang-sv: filename=gruut_lang_sv-2.0.0-py3-none-any.whl size=2851739 sha256=d5c33a6b052865df033dd1ec08b7d3f20b7e083b7444aaed1a4a323a7e15bf27\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/97/85/80f8b114b45c1642b535ac2c4d9dd9f0c94529916ac20b6d24\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=8d496e12a4e1a5b0682b5bee58077c43904ebe6c6157568b0bf6ebda53cfb38a\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.7-py3-none-any.whl size=54286 sha256=59a1be3511508352e195edb1d8ca3f0bee3afe45168668c1947dfad0e8dd6bd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/2a/f8/7bd5dcec71bd5c669f6f574db3113513696b98f3f9b51f496c\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68727 sha256=2d0ef92e90ce5885ae23cc6592a44d351adafce67a118fca69276c76ac01a464\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built bokeh gruut librosa pyworld umap-learn unidic-lite gruut-ipa gruut-lang-cs gruut-lang-de gruut-lang-en gruut-lang-es gruut-lang-fr gruut-lang-it gruut-lang-nl gruut-lang-pt gruut-lang-ru gruut-lang-sv docopt pynndescent wrapt\n",
            "Installing collected packages: regex, llvmlite, docopt, python-crfsuite, numba, num2words, MarkupSafe, jsonlines, gruut-lang-en, gruut-ipa, dateparser, wrapt, Werkzeug, typed-ast, tensorboardX, pynndescent, lazy-object-proxy, Jinja2, itsdangerous, gruut-lang-sv, gruut-lang-ru, gruut-lang-pt, gruut-lang-nl, gruut-lang-it, gruut-lang-fr, gruut-lang-es, gruut-lang-de, gruut-lang-cs, gruut, fsspec, cython, coqpit, click, unidic-lite, umap-learn, trainer, pyworld, pysbd, pypinyin, platformdirs, pathspec, mypy-extensions, mecab-python3, mccabe, librosa, isort, inflect, flask, astroid, anyascii, TTS, pylint, nose2, coverage, bokeh, black\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2022.6.2\n",
            "    Uninstalling regex-2022.6.2:\n",
            "      Successfully uninstalled regex-2022.6.2\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.0\n",
            "    Uninstalling llvmlite-0.39.0:\n",
            "      Successfully uninstalled llvmlite-0.39.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.0\n",
            "    Uninstalling numba-0.56.0:\n",
            "      Successfully uninstalled numba-0.56.0\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.0.1\n",
            "    Uninstalling MarkupSafe-2.0.1:\n",
            "      Successfully uninstalled MarkupSafe-2.0.1\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "  Attempting uninstall: itsdangerous\n",
            "    Found existing installation: itsdangerous 1.1.0\n",
            "    Uninstalling itsdangerous-1.1.0:\n",
            "      Successfully uninstalled itsdangerous-1.1.0\n",
            "  Attempting uninstall: cython\n",
            "    Found existing installation: Cython 0.29.32\n",
            "    Uninstalling Cython-0.29.32:\n",
            "      Successfully uninstalled Cython-0.29.32\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.8.1\n",
            "    Uninstalling librosa-0.8.1:\n",
            "      Successfully uninstalled librosa-0.8.1\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 2.1.0\n",
            "    Uninstalling inflect-2.1.0:\n",
            "      Successfully uninstalled inflect-2.1.0\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Running setup.py develop for TTS\n",
            "  Attempting uninstall: bokeh\n",
            "    Found existing installation: bokeh 2.3.3\n",
            "    Uninstalling bokeh-2.3.3:\n",
            "      Successfully uninstalled bokeh-2.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.12.1 requires bokeh<2.4.0,>=2.3.0, but you have bokeh 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.1 TTS Werkzeug-2.2.1 anyascii-0.3.1 astroid-2.7.3 black-22.6.0 bokeh-1.4.0 click-8.1.3 coqpit-0.0.16 coverage-6.4.2 cython-0.29.28 dateparser-1.1.1 docopt-0.6.2 flask-2.2.1 fsspec-2022.7.1 gruut-2.2.3 gruut-ipa-0.13.0 gruut-lang-cs-2.0.0 gruut-lang-de-2.0.0 gruut-lang-en-2.0.0 gruut-lang-es-2.0.0 gruut-lang-fr-2.0.2 gruut-lang-it-2.0.0 gruut-lang-nl-2.0.2 gruut-lang-pt-2.0.0 gruut-lang-ru-2.0.0 gruut-lang-sv-2.0.0 inflect-5.6.0 isort-5.10.1 itsdangerous-2.1.2 jsonlines-1.2.0 lazy-object-proxy-1.7.1 librosa-0.8.0 llvmlite-0.38.1 mccabe-0.6.1 mecab-python3-1.0.5 mypy-extensions-0.4.3 nose2-0.12.0 num2words-0.5.11 numba-0.55.1 pathspec-0.9.0 platformdirs-2.5.2 pylint-2.10.2 pynndescent-0.5.7 pypinyin-0.47.0 pysbd-0.3.4 python-crfsuite-0.9.8 pyworld-0.2.10 regex-2022.3.2 tensorboardX-2.5.1 trainer-0.0.13 typed-ast-1.4.3 umap-learn-0.5.1 unidic-lite-1.0.8 wrapt-1.12.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "/content/drive/MyDrive/VoiceCloning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Don't forget to change python dataset path and config values before training via the colab text editor! (its under the configs folder)"
      ],
      "metadata": {
        "id": "wciK-C7_iHaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install TTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5FVj0INg7rz",
        "outputId": "9dd1e4a4-84c7-4cdf-84bf-5adae1bfbb99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting TTS\n",
            "  Downloading TTS-0.7.1.tar.gz (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 14.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba==0.55.1 in /usr/local/lib/python3.7/dist-packages (from TTS) (0.55.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.7/dist-packages (from TTS) (0.47.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from TTS) (3.2.2)\n",
            "Requirement already satisfied: gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3 in /usr/local/lib/python3.7/dist-packages (from TTS) (2.2.3)\n",
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.7/dist-packages (from TTS) (0.8.0)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.7/dist-packages (from TTS) (0.0.16)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from TTS) (0.10.3.post1)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from TTS) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from TTS) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from TTS) (1.7.3)\n",
            "Requirement already satisfied: pyworld==0.2.10 in /usr/local/lib/python3.7/dist-packages (from TTS) (0.2.10)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from TTS) (1.12.0+cu113)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.7/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: trainer in /usr/local/lib/python3.7/dist-packages (from TTS) (0.0.13)\n",
            "Requirement already satisfied: umap-learn==0.5.1 in /usr/local/lib/python3.7/dist-packages (from TTS) (0.5.1)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.7/dist-packages (from TTS) (2022.7.1)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from TTS) (0.3.1)\n",
            "Requirement already satisfied: cython==0.29.28 in /usr/local/lib/python3.7/dist-packages (from TTS) (0.29.28)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from TTS) (4.64.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from TTS) (0.12.0+cu113)\n",
            "Requirement already satisfied: mecab-python3==1.0.5 in /usr/local/lib/python3.7/dist-packages (from TTS) (1.0.5)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (from TTS) (5.6.0)\n",
            "Requirement already satisfied: unidic-lite==1.0.8 in /usr/local/lib/python3.7/dist-packages (from TTS) (1.0.8)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from TTS) (2.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from TTS) (3.13)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: num2words<1.0.0,>=0.5.10 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (0.5.11)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (1.1.1)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.6.3)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.10.3)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (0.9.8)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (5.9.0)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-nl~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: gruut-lang-it~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-cs~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-ru~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: gruut-lang-pt~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: gruut-lang-sv~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS) (0.3.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS) (1.1.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS) (1.6.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa==0.8.0->TTS) (2.1.9)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.7/dist-packages (from numba==0.55.1->TTS) (0.38.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.55.1->TTS) (57.4.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn==0.5.1->TTS) (0.5.7)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from Babel<3.0.0,>=2.8.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2022.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser~=1.1.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2022.3.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser~=1.1.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser~=1.1.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from jsonlines~=1.2.0->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (1.15.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words<1.0.0,>=0.5.10->gruut[cs,de,es,fr,it,nl,pt,ru,sv]==2.2.3->TTS) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (21.3)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->pooch>=1.0->librosa==0.8.0->TTS) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->TTS) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7->TTS) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from flask->TTS) (4.12.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from flask->TTS) (2.2.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.7/dist-packages (from flask->TTS) (3.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.7/dist-packages (from flask->TTS) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.7/dist-packages (from flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6.0->flask->TTS) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3.0->flask->TTS) (2.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from trainer->TTS) (3.17.3)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from trainer->TTS) (2.5.1)\n",
            "Building wheels for collected packages: TTS\n",
            "  Building wheel for TTS (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TTS: filename=TTS-0.7.1-cp37-cp37m-linux_x86_64.whl size=606367 sha256=59b946727bec3ab299b69c97b0da0023494a82e6bb544e654330538282953b8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/cd/b0/2b38727c9eea3d7c4f89b4adfe689eac7286fb7117e47f8246\n",
            "Successfully built TTS\n",
            "Installing collected packages: TTS\n",
            "Successfully installed TTS-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # # running it for the first time? don't change this. \n",
        "# # # resuming? get the path to your latest .tar file and use that\n",
        "\n",
        "resume_from = \"/content/drive/MyDrive/VoiceCloning/models/vits_model.tar\"\n",
        "!python /content/drive/MyDrive/VoiceCloning/configs/train_vits.py --restore_path {resume_from}\n",
        "\n",
        "# !python /content/drive/MyDrive/VoiceCloning/configs/train_vits.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW8QWttoeR3D",
        "outputId": "410713ec-501d-4083-b478-befab705773f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:42:47) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 1/3 -- GLOBAL_STEP: 1001775\u001b[0m\n",
            "     | > loss_disc: 2.96153  (2.96153)\n",
            "     | > loss_disc_real_0: 0.09741  (0.09741)\n",
            "     | > loss_disc_real_1: 0.22970  (0.22970)\n",
            "     | > loss_disc_real_2: 0.23028  (0.23028)\n",
            "     | > loss_disc_real_3: 0.22745  (0.22745)\n",
            "     | > loss_disc_real_4: 0.23409  (0.23409)\n",
            "     | > loss_disc_real_5: 0.25085  (0.25085)\n",
            "     | > loss_0: 2.96153  (2.96153)\n",
            "     | > grad_norm_0: 12.50793  (12.50793)\n",
            "     | > loss_gen: 1.51726  (1.51726)\n",
            "     | > loss_kl: 0.77074  (0.77074)\n",
            "     | > loss_feat: 1.15159  (1.15159)\n",
            "     | > loss_mel: 15.87853  (15.87853)\n",
            "     | > loss_duration: 1.53045  (1.53045)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 20.84858  (20.84858)\n",
            "     | > grad_norm_1: 76.51583  (76.51583)\n",
            "     | > current_lr_0: 0.00019 \n",
            "     | > current_lr_1: 0.00019 \n",
            "     | > step_time: 0.57100  (0.57103)\n",
            "     | > loader_time: 0.02600  (0.02602)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.01692  (3.01692)\n",
            "     | > loss_disc_real_0: 0.18491  (0.18491)\n",
            "     | > loss_disc_real_1: 0.27680  (0.27680)\n",
            "     | > loss_disc_real_2: 0.25672  (0.25672)\n",
            "     | > loss_disc_real_3: 0.25617  (0.25617)\n",
            "     | > loss_disc_real_4: 0.25945  (0.25945)\n",
            "     | > loss_disc_real_5: 0.25163  (0.25163)\n",
            "     | > loss_0: 3.01692  (3.01692)\n",
            "     | > loss_gen: 1.51916  (1.51916)\n",
            "     | > loss_kl: 4.63416  (4.63416)\n",
            "     | > loss_feat: 1.11748  (1.11748)\n",
            "     | > loss_mel: 16.32803  (16.32803)\n",
            "     | > loss_duration: 3.20599  (3.20599)\n",
            "     | > loss_1: 26.80482  (26.80482)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19224 \u001b[0m(+0.01434)\n",
            "     | > avg_loss_disc:\u001b[91m 3.01692 \u001b[0m(+0.25975)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.18491 \u001b[0m(+0.07007)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.27680 \u001b[0m(+0.04774)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.25672 \u001b[0m(+0.02339)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.25617 \u001b[0m(+0.05105)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.25945 \u001b[0m(+0.03031)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.25163 \u001b[0m(+0.01877)\n",
            "     | > avg_loss_0:\u001b[91m 3.01692 \u001b[0m(+0.25975)\n",
            "     | > avg_loss_gen:\u001b[92m 1.51916 \u001b[0m(-0.03575)\n",
            "     | > avg_loss_kl:\u001b[92m 4.63416 \u001b[0m(-0.42654)\n",
            "     | > avg_loss_feat:\u001b[92m 1.11748 \u001b[0m(-0.16393)\n",
            "     | > avg_loss_mel:\u001b[91m 16.32803 \u001b[0m(+0.48661)\n",
            "     | > avg_loss_duration:\u001b[92m 3.20599 \u001b[0m(-0.39481)\n",
            "     | > avg_loss_1:\u001b[92m 26.80482 \u001b[0m(-0.53443)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 592/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:42:53) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.77865  (2.77865)\n",
            "     | > loss_disc_real_0: 0.26939  (0.26939)\n",
            "     | > loss_disc_real_1: 0.20415  (0.20415)\n",
            "     | > loss_disc_real_2: 0.18639  (0.18639)\n",
            "     | > loss_disc_real_3: 0.19118  (0.19118)\n",
            "     | > loss_disc_real_4: 0.20388  (0.20388)\n",
            "     | > loss_disc_real_5: 0.19535  (0.19535)\n",
            "     | > loss_0: 2.77865  (2.77865)\n",
            "     | > loss_gen: 1.55239  (1.55239)\n",
            "     | > loss_kl: 4.52323  (4.52323)\n",
            "     | > loss_feat: 1.75881  (1.75881)\n",
            "     | > loss_mel: 16.45405  (16.45405)\n",
            "     | > loss_duration: 3.35772  (3.35772)\n",
            "     | > loss_1: 27.64620  (27.64620)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17584 \u001b[0m(-0.01640)\n",
            "     | > avg_loss_disc:\u001b[92m 2.77865 \u001b[0m(-0.23827)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.26939 \u001b[0m(+0.08447)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20415 \u001b[0m(-0.07265)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.18639 \u001b[0m(-0.07034)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.19118 \u001b[0m(-0.06499)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20388 \u001b[0m(-0.05557)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.19535 \u001b[0m(-0.05628)\n",
            "     | > avg_loss_0:\u001b[92m 2.77865 \u001b[0m(-0.23827)\n",
            "     | > avg_loss_gen:\u001b[91m 1.55239 \u001b[0m(+0.03323)\n",
            "     | > avg_loss_kl:\u001b[92m 4.52323 \u001b[0m(-0.11094)\n",
            "     | > avg_loss_feat:\u001b[91m 1.75881 \u001b[0m(+0.64133)\n",
            "     | > avg_loss_mel:\u001b[91m 16.45405 \u001b[0m(+0.12602)\n",
            "     | > avg_loss_duration:\u001b[91m 3.35772 \u001b[0m(+0.15173)\n",
            "     | > avg_loss_1:\u001b[91m 27.64620 \u001b[0m(+0.84138)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 593/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:42:59) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.90408  (2.90408)\n",
            "     | > loss_disc_real_0: 0.27257  (0.27257)\n",
            "     | > loss_disc_real_1: 0.22892  (0.22892)\n",
            "     | > loss_disc_real_2: 0.22745  (0.22745)\n",
            "     | > loss_disc_real_3: 0.22698  (0.22698)\n",
            "     | > loss_disc_real_4: 0.23005  (0.23005)\n",
            "     | > loss_disc_real_5: 0.22396  (0.22396)\n",
            "     | > loss_0: 2.90408  (2.90408)\n",
            "     | > loss_gen: 1.55357  (1.55357)\n",
            "     | > loss_kl: 4.43322  (4.43322)\n",
            "     | > loss_feat: 0.89924  (0.89924)\n",
            "     | > loss_mel: 16.48696  (16.48696)\n",
            "     | > loss_duration: 3.38037  (3.38037)\n",
            "     | > loss_1: 26.75336  (26.75336)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18531 \u001b[0m(+0.00947)\n",
            "     | > avg_loss_disc:\u001b[91m 2.90408 \u001b[0m(+0.12543)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.27257 \u001b[0m(+0.00319)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.22892 \u001b[0m(+0.02477)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.22745 \u001b[0m(+0.04106)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.22698 \u001b[0m(+0.03579)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.23005 \u001b[0m(+0.02617)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.22396 \u001b[0m(+0.02861)\n",
            "     | > avg_loss_0:\u001b[91m 2.90408 \u001b[0m(+0.12543)\n",
            "     | > avg_loss_gen:\u001b[91m 1.55357 \u001b[0m(+0.00118)\n",
            "     | > avg_loss_kl:\u001b[92m 4.43322 \u001b[0m(-0.09001)\n",
            "     | > avg_loss_feat:\u001b[92m 0.89924 \u001b[0m(-0.85957)\n",
            "     | > avg_loss_mel:\u001b[91m 16.48696 \u001b[0m(+0.03291)\n",
            "     | > avg_loss_duration:\u001b[91m 3.38037 \u001b[0m(+0.02265)\n",
            "     | > avg_loss_1:\u001b[92m 26.75336 \u001b[0m(-0.89284)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 594/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:05) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.77538  (2.77538)\n",
            "     | > loss_disc_real_0: 0.15428  (0.15428)\n",
            "     | > loss_disc_real_1: 0.20983  (0.20983)\n",
            "     | > loss_disc_real_2: 0.20399  (0.20399)\n",
            "     | > loss_disc_real_3: 0.17814  (0.17814)\n",
            "     | > loss_disc_real_4: 0.20880  (0.20880)\n",
            "     | > loss_disc_real_5: 0.20108  (0.20108)\n",
            "     | > loss_0: 2.77538  (2.77538)\n",
            "     | > loss_gen: 1.45598  (1.45598)\n",
            "     | > loss_kl: 3.94018  (3.94018)\n",
            "     | > loss_feat: 1.34434  (1.34434)\n",
            "     | > loss_mel: 15.99878  (15.99878)\n",
            "     | > loss_duration: 3.49276  (3.49276)\n",
            "     | > loss_1: 26.23204  (26.23204)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18051 \u001b[0m(-0.00480)\n",
            "     | > avg_loss_disc:\u001b[92m 2.77538 \u001b[0m(-0.12870)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.15428 \u001b[0m(-0.11830)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20983 \u001b[0m(-0.01908)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.20399 \u001b[0m(-0.02346)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.17814 \u001b[0m(-0.04884)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20880 \u001b[0m(-0.02125)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.20108 \u001b[0m(-0.02288)\n",
            "     | > avg_loss_0:\u001b[92m 2.77538 \u001b[0m(-0.12870)\n",
            "     | > avg_loss_gen:\u001b[92m 1.45598 \u001b[0m(-0.09758)\n",
            "     | > avg_loss_kl:\u001b[92m 3.94018 \u001b[0m(-0.49304)\n",
            "     | > avg_loss_feat:\u001b[91m 1.34434 \u001b[0m(+0.44509)\n",
            "     | > avg_loss_mel:\u001b[92m 15.99878 \u001b[0m(-0.48818)\n",
            "     | > avg_loss_duration:\u001b[91m 3.49276 \u001b[0m(+0.11239)\n",
            "     | > avg_loss_1:\u001b[92m 26.23204 \u001b[0m(-0.52132)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 595/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:12) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.04914  (3.04914)\n",
            "     | > loss_disc_real_0: 0.10908  (0.10908)\n",
            "     | > loss_disc_real_1: 0.24735  (0.24735)\n",
            "     | > loss_disc_real_2: 0.26789  (0.26789)\n",
            "     | > loss_disc_real_3: 0.26680  (0.26680)\n",
            "     | > loss_disc_real_4: 0.27862  (0.27862)\n",
            "     | > loss_disc_real_5: 0.23216  (0.23216)\n",
            "     | > loss_0: 3.04914  (3.04914)\n",
            "     | > loss_gen: 1.53499  (1.53499)\n",
            "     | > loss_kl: 4.64785  (4.64785)\n",
            "     | > loss_feat: 1.53914  (1.53914)\n",
            "     | > loss_mel: 15.88553  (15.88553)\n",
            "     | > loss_duration: 3.66005  (3.66005)\n",
            "     | > loss_1: 27.26756  (27.26756)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18152 \u001b[0m(+0.00101)\n",
            "     | > avg_loss_disc:\u001b[91m 3.04914 \u001b[0m(+0.27376)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.10908 \u001b[0m(-0.04519)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24735 \u001b[0m(+0.03751)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26789 \u001b[0m(+0.06391)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26680 \u001b[0m(+0.08866)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.27862 \u001b[0m(+0.06982)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.23216 \u001b[0m(+0.03108)\n",
            "     | > avg_loss_0:\u001b[91m 3.04914 \u001b[0m(+0.27376)\n",
            "     | > avg_loss_gen:\u001b[91m 1.53499 \u001b[0m(+0.07901)\n",
            "     | > avg_loss_kl:\u001b[91m 4.64785 \u001b[0m(+0.70767)\n",
            "     | > avg_loss_feat:\u001b[91m 1.53914 \u001b[0m(+0.19481)\n",
            "     | > avg_loss_mel:\u001b[92m 15.88553 \u001b[0m(-0.11325)\n",
            "     | > avg_loss_duration:\u001b[91m 3.66005 \u001b[0m(+0.16728)\n",
            "     | > avg_loss_1:\u001b[91m 27.26756 \u001b[0m(+1.03553)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 596/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:18) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.07735  (3.07735)\n",
            "     | > loss_disc_real_0: 0.36990  (0.36990)\n",
            "     | > loss_disc_real_1: 0.21854  (0.21854)\n",
            "     | > loss_disc_real_2: 0.19751  (0.19751)\n",
            "     | > loss_disc_real_3: 0.24012  (0.24012)\n",
            "     | > loss_disc_real_4: 0.18698  (0.18698)\n",
            "     | > loss_disc_real_5: 0.26715  (0.26715)\n",
            "     | > loss_0: 3.07735  (3.07735)\n",
            "     | > loss_gen: 1.59426  (1.59426)\n",
            "     | > loss_kl: 4.44174  (4.44174)\n",
            "     | > loss_feat: 1.19978  (1.19978)\n",
            "     | > loss_mel: 18.35177  (18.35177)\n",
            "     | > loss_duration: 3.50512  (3.50512)\n",
            "     | > loss_1: 29.09268  (29.09268)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17975 \u001b[0m(-0.00177)\n",
            "     | > avg_loss_disc:\u001b[91m 3.07735 \u001b[0m(+0.02821)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.36990 \u001b[0m(+0.26082)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.21854 \u001b[0m(-0.02881)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.19751 \u001b[0m(-0.07038)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24012 \u001b[0m(-0.02667)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.18698 \u001b[0m(-0.09164)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.26715 \u001b[0m(+0.03498)\n",
            "     | > avg_loss_0:\u001b[91m 3.07735 \u001b[0m(+0.02821)\n",
            "     | > avg_loss_gen:\u001b[91m 1.59426 \u001b[0m(+0.05927)\n",
            "     | > avg_loss_kl:\u001b[92m 4.44174 \u001b[0m(-0.20611)\n",
            "     | > avg_loss_feat:\u001b[92m 1.19978 \u001b[0m(-0.33936)\n",
            "     | > avg_loss_mel:\u001b[91m 18.35177 \u001b[0m(+2.46623)\n",
            "     | > avg_loss_duration:\u001b[92m 3.50512 \u001b[0m(-0.15493)\n",
            "     | > avg_loss_1:\u001b[91m 29.09268 \u001b[0m(+1.82511)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 597/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:25) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.88196  (2.88196)\n",
            "     | > loss_disc_real_0: 0.16928  (0.16928)\n",
            "     | > loss_disc_real_1: 0.25179  (0.25179)\n",
            "     | > loss_disc_real_2: 0.27940  (0.27940)\n",
            "     | > loss_disc_real_3: 0.21260  (0.21260)\n",
            "     | > loss_disc_real_4: 0.29047  (0.29047)\n",
            "     | > loss_disc_real_5: 0.22139  (0.22139)\n",
            "     | > loss_0: 2.88196  (2.88196)\n",
            "     | > loss_gen: 1.61141  (1.61141)\n",
            "     | > loss_kl: 5.20470  (5.20470)\n",
            "     | > loss_feat: 1.33520  (1.33520)\n",
            "     | > loss_mel: 16.35780  (16.35780)\n",
            "     | > loss_duration: 3.55278  (3.55278)\n",
            "     | > loss_1: 28.06189  (28.06189)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17929 \u001b[0m(-0.00046)\n",
            "     | > avg_loss_disc:\u001b[92m 2.88196 \u001b[0m(-0.19539)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.16928 \u001b[0m(-0.20062)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.25179 \u001b[0m(+0.03325)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27940 \u001b[0m(+0.08189)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21260 \u001b[0m(-0.02752)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.29047 \u001b[0m(+0.10349)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22139 \u001b[0m(-0.04575)\n",
            "     | > avg_loss_0:\u001b[92m 2.88196 \u001b[0m(-0.19539)\n",
            "     | > avg_loss_gen:\u001b[91m 1.61141 \u001b[0m(+0.01715)\n",
            "     | > avg_loss_kl:\u001b[91m 5.20470 \u001b[0m(+0.76296)\n",
            "     | > avg_loss_feat:\u001b[91m 1.33520 \u001b[0m(+0.13542)\n",
            "     | > avg_loss_mel:\u001b[92m 16.35780 \u001b[0m(-1.99397)\n",
            "     | > avg_loss_duration:\u001b[91m 3.55278 \u001b[0m(+0.04766)\n",
            "     | > avg_loss_1:\u001b[92m 28.06189 \u001b[0m(-1.03079)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 598/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:32) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.93584  (2.93584)\n",
            "     | > loss_disc_real_0: 0.40021  (0.40021)\n",
            "     | > loss_disc_real_1: 0.23979  (0.23979)\n",
            "     | > loss_disc_real_2: 0.28373  (0.28373)\n",
            "     | > loss_disc_real_3: 0.27448  (0.27448)\n",
            "     | > loss_disc_real_4: 0.28084  (0.28084)\n",
            "     | > loss_disc_real_5: 0.27308  (0.27308)\n",
            "     | > loss_0: 2.93584  (2.93584)\n",
            "     | > loss_gen: 1.94416  (1.94416)\n",
            "     | > loss_kl: 4.72557  (4.72557)\n",
            "     | > loss_feat: 0.77980  (0.77980)\n",
            "     | > loss_mel: 15.75684  (15.75684)\n",
            "     | > loss_duration: 3.56339  (3.56339)\n",
            "     | > loss_1: 26.76977  (26.76977)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18127 \u001b[0m(+0.00198)\n",
            "     | > avg_loss_disc:\u001b[91m 2.93584 \u001b[0m(+0.05388)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.40021 \u001b[0m(+0.23092)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.23979 \u001b[0m(-0.01201)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.28373 \u001b[0m(+0.00434)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.27448 \u001b[0m(+0.06188)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.28084 \u001b[0m(-0.00963)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.27308 \u001b[0m(+0.05169)\n",
            "     | > avg_loss_0:\u001b[91m 2.93584 \u001b[0m(+0.05388)\n",
            "     | > avg_loss_gen:\u001b[91m 1.94416 \u001b[0m(+0.33275)\n",
            "     | > avg_loss_kl:\u001b[92m 4.72557 \u001b[0m(-0.47913)\n",
            "     | > avg_loss_feat:\u001b[92m 0.77980 \u001b[0m(-0.55539)\n",
            "     | > avg_loss_mel:\u001b[92m 15.75684 \u001b[0m(-0.60095)\n",
            "     | > avg_loss_duration:\u001b[91m 3.56339 \u001b[0m(+0.01061)\n",
            "     | > avg_loss_1:\u001b[92m 26.76977 \u001b[0m(-1.29212)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 599/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:38) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 2/3 -- GLOBAL_STEP: 1001800\u001b[0m\n",
            "     | > loss_disc: 2.87469  (2.82162)\n",
            "     | > loss_disc_real_0: 0.20828  (0.26294)\n",
            "     | > loss_disc_real_1: 0.22287  (0.21414)\n",
            "     | > loss_disc_real_2: 0.22333  (0.22277)\n",
            "     | > loss_disc_real_3: 0.27290  (0.24173)\n",
            "     | > loss_disc_real_4: 0.21243  (0.20671)\n",
            "     | > loss_disc_real_5: 0.24345  (0.23833)\n",
            "     | > loss_0: 2.87469  (2.82162)\n",
            "     | > grad_norm_0: 3.73632  (8.31834)\n",
            "     | > loss_gen: 1.46915  (1.52957)\n",
            "     | > loss_kl: 0.45476  (0.52756)\n",
            "     | > loss_feat: 0.98753  (1.17985)\n",
            "     | > loss_mel: 14.48368  (14.63371)\n",
            "     | > loss_duration: 1.49035  (1.45300)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 18.88547  (19.32369)\n",
            "     | > grad_norm_1: 94.39953  (68.07673)\n",
            "     | > current_lr_0: 0.00019 \n",
            "     | > current_lr_1: 0.00019 \n",
            "     | > step_time: 0.55370  (0.55265)\n",
            "     | > loader_time: 0.01480  (0.01713)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.01038  (3.01038)\n",
            "     | > loss_disc_real_0: 0.15573  (0.15573)\n",
            "     | > loss_disc_real_1: 0.22708  (0.22708)\n",
            "     | > loss_disc_real_2: 0.20964  (0.20964)\n",
            "     | > loss_disc_real_3: 0.22594  (0.22594)\n",
            "     | > loss_disc_real_4: 0.19215  (0.19215)\n",
            "     | > loss_disc_real_5: 0.22757  (0.22757)\n",
            "     | > loss_0: 3.01038  (3.01038)\n",
            "     | > loss_gen: 1.30747  (1.30747)\n",
            "     | > loss_kl: 4.34462  (4.34462)\n",
            "     | > loss_feat: 0.92904  (0.92904)\n",
            "     | > loss_mel: 15.03578  (15.03578)\n",
            "     | > loss_duration: 3.54314  (3.54314)\n",
            "     | > loss_1: 25.16006  (25.16006)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17835 \u001b[0m(-0.00293)\n",
            "     | > avg_loss_disc:\u001b[91m 3.01038 \u001b[0m(+0.07454)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.15573 \u001b[0m(-0.24448)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.22708 \u001b[0m(-0.01271)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.20964 \u001b[0m(-0.07410)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22594 \u001b[0m(-0.04855)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.19215 \u001b[0m(-0.08869)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22757 \u001b[0m(-0.04551)\n",
            "     | > avg_loss_0:\u001b[91m 3.01038 \u001b[0m(+0.07454)\n",
            "     | > avg_loss_gen:\u001b[92m 1.30747 \u001b[0m(-0.63668)\n",
            "     | > avg_loss_kl:\u001b[92m 4.34462 \u001b[0m(-0.38095)\n",
            "     | > avg_loss_feat:\u001b[91m 0.92904 \u001b[0m(+0.14924)\n",
            "     | > avg_loss_mel:\u001b[92m 15.03578 \u001b[0m(-0.72106)\n",
            "     | > avg_loss_duration:\u001b[92m 3.54314 \u001b[0m(-0.02025)\n",
            "     | > avg_loss_1:\u001b[92m 25.16006 \u001b[0m(-1.60971)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 600/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:44) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.78028  (2.78028)\n",
            "     | > loss_disc_real_0: 0.18164  (0.18164)\n",
            "     | > loss_disc_real_1: 0.24799  (0.24799)\n",
            "     | > loss_disc_real_2: 0.24992  (0.24992)\n",
            "     | > loss_disc_real_3: 0.21315  (0.21315)\n",
            "     | > loss_disc_real_4: 0.24404  (0.24404)\n",
            "     | > loss_disc_real_5: 0.23890  (0.23890)\n",
            "     | > loss_0: 2.78028  (2.78028)\n",
            "     | > loss_gen: 1.68539  (1.68539)\n",
            "     | > loss_kl: 4.47763  (4.47763)\n",
            "     | > loss_feat: 1.20277  (1.20277)\n",
            "     | > loss_mel: 15.94427  (15.94427)\n",
            "     | > loss_duration: 3.54646  (3.54646)\n",
            "     | > loss_1: 26.85652  (26.85652)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18280 \u001b[0m(+0.00445)\n",
            "     | > avg_loss_disc:\u001b[92m 2.78028 \u001b[0m(-0.23010)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.18164 \u001b[0m(+0.02591)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24799 \u001b[0m(+0.02092)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.24992 \u001b[0m(+0.04028)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21315 \u001b[0m(-0.01279)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.24404 \u001b[0m(+0.05189)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.23890 \u001b[0m(+0.01133)\n",
            "     | > avg_loss_0:\u001b[92m 2.78028 \u001b[0m(-0.23010)\n",
            "     | > avg_loss_gen:\u001b[91m 1.68539 \u001b[0m(+0.37791)\n",
            "     | > avg_loss_kl:\u001b[91m 4.47763 \u001b[0m(+0.13301)\n",
            "     | > avg_loss_feat:\u001b[91m 1.20277 \u001b[0m(+0.27373)\n",
            "     | > avg_loss_mel:\u001b[91m 15.94427 \u001b[0m(+0.90849)\n",
            "     | > avg_loss_duration:\u001b[91m 3.54646 \u001b[0m(+0.00332)\n",
            "     | > avg_loss_1:\u001b[91m 26.85652 \u001b[0m(+1.69646)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 601/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:51) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.68668  (2.68668)\n",
            "     | > loss_disc_real_0: 0.17323  (0.17323)\n",
            "     | > loss_disc_real_1: 0.17970  (0.17970)\n",
            "     | > loss_disc_real_2: 0.18790  (0.18790)\n",
            "     | > loss_disc_real_3: 0.22965  (0.22965)\n",
            "     | > loss_disc_real_4: 0.20730  (0.20730)\n",
            "     | > loss_disc_real_5: 0.20679  (0.20679)\n",
            "     | > loss_0: 2.68668  (2.68668)\n",
            "     | > loss_gen: 1.57610  (1.57610)\n",
            "     | > loss_kl: 4.90493  (4.90493)\n",
            "     | > loss_feat: 1.70160  (1.70160)\n",
            "     | > loss_mel: 16.74386  (16.74386)\n",
            "     | > loss_duration: 3.38180  (3.38180)\n",
            "     | > loss_1: 28.30830  (28.30830)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19450 \u001b[0m(+0.01170)\n",
            "     | > avg_loss_disc:\u001b[92m 2.68668 \u001b[0m(-0.09359)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.17323 \u001b[0m(-0.00841)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.17970 \u001b[0m(-0.06829)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.18790 \u001b[0m(-0.06202)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.22965 \u001b[0m(+0.01650)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20730 \u001b[0m(-0.03674)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.20679 \u001b[0m(-0.03211)\n",
            "     | > avg_loss_0:\u001b[92m 2.68668 \u001b[0m(-0.09359)\n",
            "     | > avg_loss_gen:\u001b[92m 1.57610 \u001b[0m(-0.10928)\n",
            "     | > avg_loss_kl:\u001b[91m 4.90493 \u001b[0m(+0.42729)\n",
            "     | > avg_loss_feat:\u001b[91m 1.70160 \u001b[0m(+0.49883)\n",
            "     | > avg_loss_mel:\u001b[91m 16.74386 \u001b[0m(+0.79959)\n",
            "     | > avg_loss_duration:\u001b[92m 3.38180 \u001b[0m(-0.16465)\n",
            "     | > avg_loss_1:\u001b[91m 28.30830 \u001b[0m(+1.45177)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 602/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:43:57) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.85133  (2.85133)\n",
            "     | > loss_disc_real_0: 0.27970  (0.27970)\n",
            "     | > loss_disc_real_1: 0.29500  (0.29500)\n",
            "     | > loss_disc_real_2: 0.27206  (0.27206)\n",
            "     | > loss_disc_real_3: 0.21222  (0.21222)\n",
            "     | > loss_disc_real_4: 0.22600  (0.22600)\n",
            "     | > loss_disc_real_5: 0.26715  (0.26715)\n",
            "     | > loss_0: 2.85133  (2.85133)\n",
            "     | > loss_gen: 1.92708  (1.92708)\n",
            "     | > loss_kl: 5.15975  (5.15975)\n",
            "     | > loss_feat: 1.51947  (1.51947)\n",
            "     | > loss_mel: 15.95845  (15.95845)\n",
            "     | > loss_duration: 3.51704  (3.51704)\n",
            "     | > loss_1: 28.08178  (28.08178)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18728 \u001b[0m(-0.00722)\n",
            "     | > avg_loss_disc:\u001b[91m 2.85133 \u001b[0m(+0.16464)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.27970 \u001b[0m(+0.10647)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.29500 \u001b[0m(+0.11530)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27206 \u001b[0m(+0.08417)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21222 \u001b[0m(-0.01743)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.22600 \u001b[0m(+0.01870)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.26715 \u001b[0m(+0.06035)\n",
            "     | > avg_loss_0:\u001b[91m 2.85133 \u001b[0m(+0.16464)\n",
            "     | > avg_loss_gen:\u001b[91m 1.92708 \u001b[0m(+0.35097)\n",
            "     | > avg_loss_kl:\u001b[91m 5.15975 \u001b[0m(+0.25482)\n",
            "     | > avg_loss_feat:\u001b[92m 1.51947 \u001b[0m(-0.18214)\n",
            "     | > avg_loss_mel:\u001b[92m 15.95845 \u001b[0m(-0.78541)\n",
            "     | > avg_loss_duration:\u001b[91m 3.51704 \u001b[0m(+0.13523)\n",
            "     | > avg_loss_1:\u001b[92m 28.08178 \u001b[0m(-0.22651)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 603/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:03) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.00323  (3.00323)\n",
            "     | > loss_disc_real_0: 0.28108  (0.28108)\n",
            "     | > loss_disc_real_1: 0.24456  (0.24456)\n",
            "     | > loss_disc_real_2: 0.32734  (0.32734)\n",
            "     | > loss_disc_real_3: 0.27165  (0.27165)\n",
            "     | > loss_disc_real_4: 0.23857  (0.23857)\n",
            "     | > loss_disc_real_5: 0.28413  (0.28413)\n",
            "     | > loss_0: 3.00323  (3.00323)\n",
            "     | > loss_gen: 1.70798  (1.70798)\n",
            "     | > loss_kl: 4.13883  (4.13883)\n",
            "     | > loss_feat: 1.28312  (1.28312)\n",
            "     | > loss_mel: 16.83323  (16.83323)\n",
            "     | > loss_duration: 3.54214  (3.54214)\n",
            "     | > loss_1: 27.50530  (27.50530)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18075 \u001b[0m(-0.00653)\n",
            "     | > avg_loss_disc:\u001b[91m 3.00323 \u001b[0m(+0.15190)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.28108 \u001b[0m(+0.00138)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.24456 \u001b[0m(-0.05044)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.32734 \u001b[0m(+0.05528)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.27165 \u001b[0m(+0.05943)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.23857 \u001b[0m(+0.01257)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.28413 \u001b[0m(+0.01698)\n",
            "     | > avg_loss_0:\u001b[91m 3.00323 \u001b[0m(+0.15190)\n",
            "     | > avg_loss_gen:\u001b[92m 1.70798 \u001b[0m(-0.21910)\n",
            "     | > avg_loss_kl:\u001b[92m 4.13883 \u001b[0m(-1.02092)\n",
            "     | > avg_loss_feat:\u001b[92m 1.28312 \u001b[0m(-0.23635)\n",
            "     | > avg_loss_mel:\u001b[91m 16.83323 \u001b[0m(+0.87478)\n",
            "     | > avg_loss_duration:\u001b[91m 3.54214 \u001b[0m(+0.02511)\n",
            "     | > avg_loss_1:\u001b[92m 27.50530 \u001b[0m(-0.57648)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 604/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:09) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.83944  (2.83944)\n",
            "     | > loss_disc_real_0: 0.16855  (0.16855)\n",
            "     | > loss_disc_real_1: 0.24597  (0.24597)\n",
            "     | > loss_disc_real_2: 0.22693  (0.22693)\n",
            "     | > loss_disc_real_3: 0.24912  (0.24912)\n",
            "     | > loss_disc_real_4: 0.25461  (0.25461)\n",
            "     | > loss_disc_real_5: 0.24227  (0.24227)\n",
            "     | > loss_0: 2.83944  (2.83944)\n",
            "     | > loss_gen: 1.59232  (1.59232)\n",
            "     | > loss_kl: 4.58181  (4.58181)\n",
            "     | > loss_feat: 0.66175  (0.66175)\n",
            "     | > loss_mel: 14.77944  (14.77944)\n",
            "     | > loss_duration: 3.34595  (3.34595)\n",
            "     | > loss_1: 24.96128  (24.96128)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18203 \u001b[0m(+0.00128)\n",
            "     | > avg_loss_disc:\u001b[92m 2.83944 \u001b[0m(-0.16379)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.16855 \u001b[0m(-0.11253)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24597 \u001b[0m(+0.00141)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.22693 \u001b[0m(-0.10041)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24912 \u001b[0m(-0.02253)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.25461 \u001b[0m(+0.01604)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24227 \u001b[0m(-0.04185)\n",
            "     | > avg_loss_0:\u001b[92m 2.83944 \u001b[0m(-0.16379)\n",
            "     | > avg_loss_gen:\u001b[92m 1.59232 \u001b[0m(-0.11566)\n",
            "     | > avg_loss_kl:\u001b[91m 4.58181 \u001b[0m(+0.44298)\n",
            "     | > avg_loss_feat:\u001b[92m 0.66175 \u001b[0m(-0.62137)\n",
            "     | > avg_loss_mel:\u001b[92m 14.77944 \u001b[0m(-2.05379)\n",
            "     | > avg_loss_duration:\u001b[92m 3.34595 \u001b[0m(-0.19619)\n",
            "     | > avg_loss_1:\u001b[92m 24.96128 \u001b[0m(-2.54403)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 605/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:15) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.84367  (2.84367)\n",
            "     | > loss_disc_real_0: 0.13038  (0.13038)\n",
            "     | > loss_disc_real_1: 0.27037  (0.27037)\n",
            "     | > loss_disc_real_2: 0.24217  (0.24217)\n",
            "     | > loss_disc_real_3: 0.22426  (0.22426)\n",
            "     | > loss_disc_real_4: 0.23595  (0.23595)\n",
            "     | > loss_disc_real_5: 0.22777  (0.22777)\n",
            "     | > loss_0: 2.84367  (2.84367)\n",
            "     | > loss_gen: 1.52922  (1.52922)\n",
            "     | > loss_kl: 4.36049  (4.36049)\n",
            "     | > loss_feat: 0.94453  (0.94453)\n",
            "     | > loss_mel: 15.18551  (15.18551)\n",
            "     | > loss_duration: 3.46093  (3.46093)\n",
            "     | > loss_1: 25.48068  (25.48068)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18307 \u001b[0m(+0.00103)\n",
            "     | > avg_loss_disc:\u001b[91m 2.84367 \u001b[0m(+0.00423)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.13038 \u001b[0m(-0.03817)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.27037 \u001b[0m(+0.02440)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.24217 \u001b[0m(+0.01524)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22426 \u001b[0m(-0.02486)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.23595 \u001b[0m(-0.01866)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22777 \u001b[0m(-0.01450)\n",
            "     | > avg_loss_0:\u001b[91m 2.84367 \u001b[0m(+0.00423)\n",
            "     | > avg_loss_gen:\u001b[92m 1.52922 \u001b[0m(-0.06310)\n",
            "     | > avg_loss_kl:\u001b[92m 4.36049 \u001b[0m(-0.22132)\n",
            "     | > avg_loss_feat:\u001b[91m 0.94453 \u001b[0m(+0.28278)\n",
            "     | > avg_loss_mel:\u001b[91m 15.18551 \u001b[0m(+0.40606)\n",
            "     | > avg_loss_duration:\u001b[91m 3.46093 \u001b[0m(+0.11498)\n",
            "     | > avg_loss_1:\u001b[91m 25.48068 \u001b[0m(+0.51940)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 606/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:22) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.77622  (2.77622)\n",
            "     | > loss_disc_real_0: 0.18319  (0.18319)\n",
            "     | > loss_disc_real_1: 0.21638  (0.21638)\n",
            "     | > loss_disc_real_2: 0.24914  (0.24914)\n",
            "     | > loss_disc_real_3: 0.26318  (0.26318)\n",
            "     | > loss_disc_real_4: 0.23583  (0.23583)\n",
            "     | > loss_disc_real_5: 0.24995  (0.24995)\n",
            "     | > loss_0: 2.77622  (2.77622)\n",
            "     | > loss_gen: 1.68396  (1.68396)\n",
            "     | > loss_kl: 5.19773  (5.19773)\n",
            "     | > loss_feat: 1.47726  (1.47726)\n",
            "     | > loss_mel: 17.28609  (17.28609)\n",
            "     | > loss_duration: 3.46153  (3.46153)\n",
            "     | > loss_1: 29.10658  (29.10658)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17944 \u001b[0m(-0.00362)\n",
            "     | > avg_loss_disc:\u001b[92m 2.77622 \u001b[0m(-0.06745)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.18319 \u001b[0m(+0.05281)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.21638 \u001b[0m(-0.05399)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.24914 \u001b[0m(+0.00697)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26318 \u001b[0m(+0.03892)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.23583 \u001b[0m(-0.00012)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.24995 \u001b[0m(+0.02218)\n",
            "     | > avg_loss_0:\u001b[92m 2.77622 \u001b[0m(-0.06745)\n",
            "     | > avg_loss_gen:\u001b[91m 1.68396 \u001b[0m(+0.15474)\n",
            "     | > avg_loss_kl:\u001b[91m 5.19773 \u001b[0m(+0.83724)\n",
            "     | > avg_loss_feat:\u001b[91m 1.47726 \u001b[0m(+0.53272)\n",
            "     | > avg_loss_mel:\u001b[91m 17.28609 \u001b[0m(+2.10059)\n",
            "     | > avg_loss_duration:\u001b[91m 3.46153 \u001b[0m(+0.00060)\n",
            "     | > avg_loss_1:\u001b[91m 29.10658 \u001b[0m(+3.62590)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 607/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:28) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.67052  (2.67052)\n",
            "     | > loss_disc_real_0: 0.25039  (0.25039)\n",
            "     | > loss_disc_real_1: 0.21792  (0.21792)\n",
            "     | > loss_disc_real_2: 0.19509  (0.19509)\n",
            "     | > loss_disc_real_3: 0.21971  (0.21971)\n",
            "     | > loss_disc_real_4: 0.20161  (0.20161)\n",
            "     | > loss_disc_real_5: 0.18885  (0.18885)\n",
            "     | > loss_0: 2.67052  (2.67052)\n",
            "     | > loss_gen: 1.78763  (1.78763)\n",
            "     | > loss_kl: 4.83625  (4.83625)\n",
            "     | > loss_feat: 1.82848  (1.82848)\n",
            "     | > loss_mel: 17.23588  (17.23588)\n",
            "     | > loss_duration: 3.54132  (3.54132)\n",
            "     | > loss_1: 29.22955  (29.22955)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18047 \u001b[0m(+0.00103)\n",
            "     | > avg_loss_disc:\u001b[92m 2.67052 \u001b[0m(-0.10570)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.25039 \u001b[0m(+0.06720)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.21792 \u001b[0m(+0.00154)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.19509 \u001b[0m(-0.05405)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21971 \u001b[0m(-0.04346)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20161 \u001b[0m(-0.03422)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.18885 \u001b[0m(-0.06110)\n",
            "     | > avg_loss_0:\u001b[92m 2.67052 \u001b[0m(-0.10570)\n",
            "     | > avg_loss_gen:\u001b[91m 1.78763 \u001b[0m(+0.10366)\n",
            "     | > avg_loss_kl:\u001b[92m 4.83625 \u001b[0m(-0.36148)\n",
            "     | > avg_loss_feat:\u001b[91m 1.82848 \u001b[0m(+0.35122)\n",
            "     | > avg_loss_mel:\u001b[92m 17.23588 \u001b[0m(-0.05021)\n",
            "     | > avg_loss_duration:\u001b[91m 3.54132 \u001b[0m(+0.07979)\n",
            "     | > avg_loss_1:\u001b[91m 29.22955 \u001b[0m(+0.12298)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 608/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:34) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0/3 -- GLOBAL_STEP: 1001825\u001b[0m\n",
            "     | > loss_disc: 2.90614  (2.90614)\n",
            "     | > loss_disc_real_0: 0.38535  (0.38535)\n",
            "     | > loss_disc_real_1: 0.24929  (0.24929)\n",
            "     | > loss_disc_real_2: 0.24387  (0.24387)\n",
            "     | > loss_disc_real_3: 0.22516  (0.22516)\n",
            "     | > loss_disc_real_4: 0.26720  (0.26720)\n",
            "     | > loss_disc_real_5: 0.25937  (0.25937)\n",
            "     | > loss_0: 2.90614  (2.90614)\n",
            "     | > grad_norm_0: 16.81582  (16.81582)\n",
            "     | > loss_gen: 1.87508  (1.87508)\n",
            "     | > loss_kl: 0.39263  (0.39263)\n",
            "     | > loss_feat: 1.14577  (1.14577)\n",
            "     | > loss_mel: 14.90545  (14.90545)\n",
            "     | > loss_duration: 1.40229  (1.40229)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 19.72123  (19.72123)\n",
            "     | > grad_norm_1: 47.99377  (47.99377)\n",
            "     | > current_lr_0: 0.00019 \n",
            "     | > current_lr_1: 0.00019 \n",
            "     | > step_time: 0.60110  (0.60109)\n",
            "     | > loader_time: 0.02370  (0.02368)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.91883  (2.91883)\n",
            "     | > loss_disc_real_0: 0.11133  (0.11133)\n",
            "     | > loss_disc_real_1: 0.19604  (0.19604)\n",
            "     | > loss_disc_real_2: 0.19355  (0.19355)\n",
            "     | > loss_disc_real_3: 0.16223  (0.16223)\n",
            "     | > loss_disc_real_4: 0.18942  (0.18942)\n",
            "     | > loss_disc_real_5: 0.19337  (0.19337)\n",
            "     | > loss_0: 2.91883  (2.91883)\n",
            "     | > loss_gen: 1.25728  (1.25728)\n",
            "     | > loss_kl: 4.80280  (4.80280)\n",
            "     | > loss_feat: 1.37293  (1.37293)\n",
            "     | > loss_mel: 18.26211  (18.26211)\n",
            "     | > loss_duration: 3.45858  (3.45858)\n",
            "     | > loss_1: 29.15370  (29.15370)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17737 \u001b[0m(-0.00311)\n",
            "     | > avg_loss_disc:\u001b[91m 2.91883 \u001b[0m(+0.24831)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.11133 \u001b[0m(-0.13906)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.19604 \u001b[0m(-0.02188)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.19355 \u001b[0m(-0.00155)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.16223 \u001b[0m(-0.05748)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.18942 \u001b[0m(-0.01220)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.19337 \u001b[0m(+0.00452)\n",
            "     | > avg_loss_0:\u001b[91m 2.91883 \u001b[0m(+0.24831)\n",
            "     | > avg_loss_gen:\u001b[92m 1.25728 \u001b[0m(-0.53035)\n",
            "     | > avg_loss_kl:\u001b[92m 4.80280 \u001b[0m(-0.03345)\n",
            "     | > avg_loss_feat:\u001b[92m 1.37293 \u001b[0m(-0.45555)\n",
            "     | > avg_loss_mel:\u001b[91m 18.26211 \u001b[0m(+1.02623)\n",
            "     | > avg_loss_duration:\u001b[92m 3.45858 \u001b[0m(-0.08274)\n",
            "     | > avg_loss_1:\u001b[92m 29.15370 \u001b[0m(-0.07586)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 609/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:40) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.94704  (2.94704)\n",
            "     | > loss_disc_real_0: 0.26828  (0.26828)\n",
            "     | > loss_disc_real_1: 0.21800  (0.21800)\n",
            "     | > loss_disc_real_2: 0.21750  (0.21750)\n",
            "     | > loss_disc_real_3: 0.20515  (0.20515)\n",
            "     | > loss_disc_real_4: 0.22602  (0.22602)\n",
            "     | > loss_disc_real_5: 0.21140  (0.21140)\n",
            "     | > loss_0: 2.94704  (2.94704)\n",
            "     | > loss_gen: 1.60646  (1.60646)\n",
            "     | > loss_kl: 4.77577  (4.77577)\n",
            "     | > loss_feat: 1.32563  (1.32563)\n",
            "     | > loss_mel: 17.26051  (17.26051)\n",
            "     | > loss_duration: 3.36495  (3.36495)\n",
            "     | > loss_1: 28.33332  (28.33332)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18391 \u001b[0m(+0.00654)\n",
            "     | > avg_loss_disc:\u001b[91m 2.94704 \u001b[0m(+0.02822)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.26828 \u001b[0m(+0.15694)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.21800 \u001b[0m(+0.02195)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.21750 \u001b[0m(+0.02395)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.20515 \u001b[0m(+0.04292)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.22602 \u001b[0m(+0.03661)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.21140 \u001b[0m(+0.01802)\n",
            "     | > avg_loss_0:\u001b[91m 2.94704 \u001b[0m(+0.02822)\n",
            "     | > avg_loss_gen:\u001b[91m 1.60646 \u001b[0m(+0.34918)\n",
            "     | > avg_loss_kl:\u001b[92m 4.77577 \u001b[0m(-0.02703)\n",
            "     | > avg_loss_feat:\u001b[92m 1.32563 \u001b[0m(-0.04730)\n",
            "     | > avg_loss_mel:\u001b[92m 17.26051 \u001b[0m(-1.00160)\n",
            "     | > avg_loss_duration:\u001b[92m 3.36495 \u001b[0m(-0.09363)\n",
            "     | > avg_loss_1:\u001b[92m 28.33332 \u001b[0m(-0.82037)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 610/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:47) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.09795  (3.09795)\n",
            "     | > loss_disc_real_0: 0.39117  (0.39117)\n",
            "     | > loss_disc_real_1: 0.26633  (0.26633)\n",
            "     | > loss_disc_real_2: 0.26811  (0.26811)\n",
            "     | > loss_disc_real_3: 0.26937  (0.26937)\n",
            "     | > loss_disc_real_4: 0.25991  (0.25991)\n",
            "     | > loss_disc_real_5: 0.29090  (0.29090)\n",
            "     | > loss_0: 3.09795  (3.09795)\n",
            "     | > loss_gen: 1.84992  (1.84992)\n",
            "     | > loss_kl: 4.92972  (4.92972)\n",
            "     | > loss_feat: 1.07118  (1.07118)\n",
            "     | > loss_mel: 14.50263  (14.50263)\n",
            "     | > loss_duration: 3.33346  (3.33346)\n",
            "     | > loss_1: 25.68691  (25.68691)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.30681 \u001b[0m(+0.12290)\n",
            "     | > avg_loss_disc:\u001b[91m 3.09795 \u001b[0m(+0.15091)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.39117 \u001b[0m(+0.12290)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.26633 \u001b[0m(+0.04833)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26811 \u001b[0m(+0.05061)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26937 \u001b[0m(+0.06422)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.25991 \u001b[0m(+0.03389)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.29090 \u001b[0m(+0.07950)\n",
            "     | > avg_loss_0:\u001b[91m 3.09795 \u001b[0m(+0.15091)\n",
            "     | > avg_loss_gen:\u001b[91m 1.84992 \u001b[0m(+0.24346)\n",
            "     | > avg_loss_kl:\u001b[91m 4.92972 \u001b[0m(+0.15396)\n",
            "     | > avg_loss_feat:\u001b[92m 1.07118 \u001b[0m(-0.25445)\n",
            "     | > avg_loss_mel:\u001b[92m 14.50263 \u001b[0m(-2.75789)\n",
            "     | > avg_loss_duration:\u001b[92m 3.33346 \u001b[0m(-0.03149)\n",
            "     | > avg_loss_1:\u001b[92m 25.68691 \u001b[0m(-2.64642)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 611/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:44:54) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.77229  (2.77229)\n",
            "     | > loss_disc_real_0: 0.06067  (0.06067)\n",
            "     | > loss_disc_real_1: 0.25140  (0.25140)\n",
            "     | > loss_disc_real_2: 0.25321  (0.25321)\n",
            "     | > loss_disc_real_3: 0.25000  (0.25000)\n",
            "     | > loss_disc_real_4: 0.23779  (0.23779)\n",
            "     | > loss_disc_real_5: 0.24023  (0.24023)\n",
            "     | > loss_0: 2.77229  (2.77229)\n",
            "     | > loss_gen: 1.56244  (1.56244)\n",
            "     | > loss_kl: 4.60404  (4.60404)\n",
            "     | > loss_feat: 1.31979  (1.31979)\n",
            "     | > loss_mel: 16.23067  (16.23067)\n",
            "     | > loss_duration: 3.25496  (3.25496)\n",
            "     | > loss_1: 26.97190  (26.97190)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17802 \u001b[0m(-0.12879)\n",
            "     | > avg_loss_disc:\u001b[92m 2.77229 \u001b[0m(-0.32566)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.06067 \u001b[0m(-0.33050)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.25140 \u001b[0m(-0.01492)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.25321 \u001b[0m(-0.01490)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.25000 \u001b[0m(-0.01937)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.23779 \u001b[0m(-0.02212)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24023 \u001b[0m(-0.05067)\n",
            "     | > avg_loss_0:\u001b[92m 2.77229 \u001b[0m(-0.32566)\n",
            "     | > avg_loss_gen:\u001b[92m 1.56244 \u001b[0m(-0.28748)\n",
            "     | > avg_loss_kl:\u001b[92m 4.60404 \u001b[0m(-0.32568)\n",
            "     | > avg_loss_feat:\u001b[91m 1.31979 \u001b[0m(+0.24861)\n",
            "     | > avg_loss_mel:\u001b[91m 16.23067 \u001b[0m(+1.72805)\n",
            "     | > avg_loss_duration:\u001b[92m 3.25496 \u001b[0m(-0.07850)\n",
            "     | > avg_loss_1:\u001b[91m 26.97190 \u001b[0m(+1.28499)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 612/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:00) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.78323  (2.78323)\n",
            "     | > loss_disc_real_0: 0.29221  (0.29221)\n",
            "     | > loss_disc_real_1: 0.28752  (0.28752)\n",
            "     | > loss_disc_real_2: 0.29771  (0.29771)\n",
            "     | > loss_disc_real_3: 0.27178  (0.27178)\n",
            "     | > loss_disc_real_4: 0.32091  (0.32091)\n",
            "     | > loss_disc_real_5: 0.28059  (0.28059)\n",
            "     | > loss_0: 2.78323  (2.78323)\n",
            "     | > loss_gen: 2.22290  (2.22290)\n",
            "     | > loss_kl: 4.38193  (4.38193)\n",
            "     | > loss_feat: 1.17731  (1.17731)\n",
            "     | > loss_mel: 14.89977  (14.89977)\n",
            "     | > loss_duration: 3.29141  (3.29141)\n",
            "     | > loss_1: 25.97331  (25.97331)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.17820 \u001b[0m(+0.00018)\n",
            "     | > avg_loss_disc:\u001b[91m 2.78323 \u001b[0m(+0.01094)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.29221 \u001b[0m(+0.23153)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.28752 \u001b[0m(+0.03612)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.29771 \u001b[0m(+0.04450)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.27178 \u001b[0m(+0.02178)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.32091 \u001b[0m(+0.08312)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.28059 \u001b[0m(+0.04036)\n",
            "     | > avg_loss_0:\u001b[91m 2.78323 \u001b[0m(+0.01094)\n",
            "     | > avg_loss_gen:\u001b[91m 2.22290 \u001b[0m(+0.66046)\n",
            "     | > avg_loss_kl:\u001b[92m 4.38193 \u001b[0m(-0.22211)\n",
            "     | > avg_loss_feat:\u001b[92m 1.17731 \u001b[0m(-0.14248)\n",
            "     | > avg_loss_mel:\u001b[92m 14.89977 \u001b[0m(-1.33091)\n",
            "     | > avg_loss_duration:\u001b[91m 3.29141 \u001b[0m(+0.03645)\n",
            "     | > avg_loss_1:\u001b[92m 25.97331 \u001b[0m(-0.99859)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 613/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:06) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.88188  (2.88188)\n",
            "     | > loss_disc_real_0: 0.09880  (0.09880)\n",
            "     | > loss_disc_real_1: 0.22744  (0.22744)\n",
            "     | > loss_disc_real_2: 0.23739  (0.23739)\n",
            "     | > loss_disc_real_3: 0.25408  (0.25408)\n",
            "     | > loss_disc_real_4: 0.22554  (0.22554)\n",
            "     | > loss_disc_real_5: 0.27172  (0.27172)\n",
            "     | > loss_0: 2.88188  (2.88188)\n",
            "     | > loss_gen: 1.49320  (1.49320)\n",
            "     | > loss_kl: 4.71720  (4.71720)\n",
            "     | > loss_feat: 1.05295  (1.05295)\n",
            "     | > loss_mel: 14.29152  (14.29152)\n",
            "     | > loss_duration: 3.46511  (3.46511)\n",
            "     | > loss_1: 25.01999  (25.01999)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18805 \u001b[0m(+0.00985)\n",
            "     | > avg_loss_disc:\u001b[91m 2.88188 \u001b[0m(+0.09865)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.09880 \u001b[0m(-0.19341)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.22744 \u001b[0m(-0.06008)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.23739 \u001b[0m(-0.06032)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.25408 \u001b[0m(-0.01770)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.22554 \u001b[0m(-0.09537)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.27172 \u001b[0m(-0.00887)\n",
            "     | > avg_loss_0:\u001b[91m 2.88188 \u001b[0m(+0.09865)\n",
            "     | > avg_loss_gen:\u001b[92m 1.49320 \u001b[0m(-0.72969)\n",
            "     | > avg_loss_kl:\u001b[91m 4.71720 \u001b[0m(+0.33527)\n",
            "     | > avg_loss_feat:\u001b[92m 1.05295 \u001b[0m(-0.12436)\n",
            "     | > avg_loss_mel:\u001b[92m 14.29152 \u001b[0m(-0.60825)\n",
            "     | > avg_loss_duration:\u001b[91m 3.46511 \u001b[0m(+0.17370)\n",
            "     | > avg_loss_1:\u001b[92m 25.01999 \u001b[0m(-0.95332)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 614/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:13) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.93642  (2.93642)\n",
            "     | > loss_disc_real_0: 0.43009  (0.43009)\n",
            "     | > loss_disc_real_1: 0.22579  (0.22579)\n",
            "     | > loss_disc_real_2: 0.17400  (0.17400)\n",
            "     | > loss_disc_real_3: 0.16602  (0.16602)\n",
            "     | > loss_disc_real_4: 0.18655  (0.18655)\n",
            "     | > loss_disc_real_5: 0.17437  (0.17437)\n",
            "     | > loss_0: 2.93642  (2.93642)\n",
            "     | > loss_gen: 1.54680  (1.54680)\n",
            "     | > loss_kl: 5.01835  (5.01835)\n",
            "     | > loss_feat: 1.60056  (1.60056)\n",
            "     | > loss_mel: 17.70361  (17.70361)\n",
            "     | > loss_duration: 3.41856  (3.41856)\n",
            "     | > loss_1: 29.28787  (29.28787)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19342 \u001b[0m(+0.00537)\n",
            "     | > avg_loss_disc:\u001b[91m 2.93642 \u001b[0m(+0.05455)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.43009 \u001b[0m(+0.33130)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.22579 \u001b[0m(-0.00165)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.17400 \u001b[0m(-0.06339)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.16602 \u001b[0m(-0.08806)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.18655 \u001b[0m(-0.03899)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.17437 \u001b[0m(-0.09735)\n",
            "     | > avg_loss_0:\u001b[91m 2.93642 \u001b[0m(+0.05455)\n",
            "     | > avg_loss_gen:\u001b[91m 1.54680 \u001b[0m(+0.05360)\n",
            "     | > avg_loss_kl:\u001b[91m 5.01835 \u001b[0m(+0.30115)\n",
            "     | > avg_loss_feat:\u001b[91m 1.60056 \u001b[0m(+0.54760)\n",
            "     | > avg_loss_mel:\u001b[91m 17.70361 \u001b[0m(+3.41209)\n",
            "     | > avg_loss_duration:\u001b[92m 3.41856 \u001b[0m(-0.04655)\n",
            "     | > avg_loss_1:\u001b[91m 29.28787 \u001b[0m(+4.26789)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 615/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:19) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.84686  (2.84686)\n",
            "     | > loss_disc_real_0: 0.24265  (0.24265)\n",
            "     | > loss_disc_real_1: 0.24186  (0.24186)\n",
            "     | > loss_disc_real_2: 0.27704  (0.27704)\n",
            "     | > loss_disc_real_3: 0.34901  (0.34901)\n",
            "     | > loss_disc_real_4: 0.30289  (0.30289)\n",
            "     | > loss_disc_real_5: 0.27666  (0.27666)\n",
            "     | > loss_0: 2.84686  (2.84686)\n",
            "     | > loss_gen: 1.94205  (1.94205)\n",
            "     | > loss_kl: 5.49447  (5.49447)\n",
            "     | > loss_feat: 1.02382  (1.02382)\n",
            "     | > loss_mel: 16.40593  (16.40593)\n",
            "     | > loss_duration: 3.53860  (3.53860)\n",
            "     | > loss_1: 28.40487  (28.40487)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.19119 \u001b[0m(-0.00223)\n",
            "     | > avg_loss_disc:\u001b[92m 2.84686 \u001b[0m(-0.08956)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.24265 \u001b[0m(-0.18744)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24186 \u001b[0m(+0.01607)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27704 \u001b[0m(+0.10304)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.34901 \u001b[0m(+0.18299)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.30289 \u001b[0m(+0.11635)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.27666 \u001b[0m(+0.10229)\n",
            "     | > avg_loss_0:\u001b[92m 2.84686 \u001b[0m(-0.08956)\n",
            "     | > avg_loss_gen:\u001b[91m 1.94205 \u001b[0m(+0.39525)\n",
            "     | > avg_loss_kl:\u001b[91m 5.49447 \u001b[0m(+0.47612)\n",
            "     | > avg_loss_feat:\u001b[92m 1.02382 \u001b[0m(-0.57674)\n",
            "     | > avg_loss_mel:\u001b[92m 16.40593 \u001b[0m(-1.29767)\n",
            "     | > avg_loss_duration:\u001b[91m 3.53860 \u001b[0m(+0.12004)\n",
            "     | > avg_loss_1:\u001b[92m 28.40487 \u001b[0m(-0.88301)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 616/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:25) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 1/3 -- GLOBAL_STEP: 1001850\u001b[0m\n",
            "     | > loss_disc: 2.75021  (2.75021)\n",
            "     | > loss_disc_real_0: 0.10592  (0.10592)\n",
            "     | > loss_disc_real_1: 0.17023  (0.17023)\n",
            "     | > loss_disc_real_2: 0.21473  (0.21473)\n",
            "     | > loss_disc_real_3: 0.20579  (0.20579)\n",
            "     | > loss_disc_real_4: 0.18730  (0.18730)\n",
            "     | > loss_disc_real_5: 0.17647  (0.17647)\n",
            "     | > loss_0: 2.75021  (2.75021)\n",
            "     | > grad_norm_0: 16.84281  (16.84281)\n",
            "     | > loss_gen: 1.58567  (1.58567)\n",
            "     | > loss_kl: 0.87808  (0.87808)\n",
            "     | > loss_feat: 2.11168  (2.11168)\n",
            "     | > loss_mel: 16.18848  (16.18848)\n",
            "     | > loss_duration: 1.38931  (1.38931)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 22.15322  (22.15322)\n",
            "     | > grad_norm_1: 113.33356  (113.33356)\n",
            "     | > current_lr_0: 0.00019 \n",
            "     | > current_lr_1: 0.00019 \n",
            "     | > step_time: 0.55650  (0.55648)\n",
            "     | > loader_time: 0.01910  (0.01910)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.87976  (2.87976)\n",
            "     | > loss_disc_real_0: 0.29568  (0.29568)\n",
            "     | > loss_disc_real_1: 0.30224  (0.30224)\n",
            "     | > loss_disc_real_2: 0.24526  (0.24526)\n",
            "     | > loss_disc_real_3: 0.24576  (0.24576)\n",
            "     | > loss_disc_real_4: 0.26023  (0.26023)\n",
            "     | > loss_disc_real_5: 0.25885  (0.25885)\n",
            "     | > loss_0: 2.87976  (2.87976)\n",
            "     | > loss_gen: 1.87488  (1.87488)\n",
            "     | > loss_kl: 5.33706  (5.33706)\n",
            "     | > loss_feat: 1.30096  (1.30096)\n",
            "     | > loss_mel: 15.81610  (15.81610)\n",
            "     | > loss_duration: 3.43436  (3.43436)\n",
            "     | > loss_1: 27.76336  (27.76336)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19468 \u001b[0m(+0.00349)\n",
            "     | > avg_loss_disc:\u001b[91m 2.87976 \u001b[0m(+0.03290)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.29568 \u001b[0m(+0.05302)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.30224 \u001b[0m(+0.06038)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.24526 \u001b[0m(-0.03178)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24576 \u001b[0m(-0.10325)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.26023 \u001b[0m(-0.04266)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.25885 \u001b[0m(-0.01782)\n",
            "     | > avg_loss_0:\u001b[91m 2.87976 \u001b[0m(+0.03290)\n",
            "     | > avg_loss_gen:\u001b[92m 1.87488 \u001b[0m(-0.06717)\n",
            "     | > avg_loss_kl:\u001b[92m 5.33706 \u001b[0m(-0.15741)\n",
            "     | > avg_loss_feat:\u001b[91m 1.30096 \u001b[0m(+0.27714)\n",
            "     | > avg_loss_mel:\u001b[92m 15.81610 \u001b[0m(-0.58984)\n",
            "     | > avg_loss_duration:\u001b[92m 3.43436 \u001b[0m(-0.10424)\n",
            "     | > avg_loss_1:\u001b[92m 27.76336 \u001b[0m(-0.64151)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 617/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:32) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.94257  (2.94257)\n",
            "     | > loss_disc_real_0: 0.14986  (0.14986)\n",
            "     | > loss_disc_real_1: 0.24546  (0.24546)\n",
            "     | > loss_disc_real_2: 0.23417  (0.23417)\n",
            "     | > loss_disc_real_3: 0.21469  (0.21469)\n",
            "     | > loss_disc_real_4: 0.23411  (0.23411)\n",
            "     | > loss_disc_real_5: 0.24669  (0.24669)\n",
            "     | > loss_0: 2.94257  (2.94257)\n",
            "     | > loss_gen: 1.46321  (1.46321)\n",
            "     | > loss_kl: 4.95474  (4.95474)\n",
            "     | > loss_feat: 1.68838  (1.68838)\n",
            "     | > loss_mel: 15.26663  (15.26663)\n",
            "     | > loss_duration: 3.36670  (3.36670)\n",
            "     | > loss_1: 26.73966  (26.73966)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18499 \u001b[0m(-0.00969)\n",
            "     | > avg_loss_disc:\u001b[91m 2.94257 \u001b[0m(+0.06281)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.14986 \u001b[0m(-0.14582)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.24546 \u001b[0m(-0.05678)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.23417 \u001b[0m(-0.01109)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21469 \u001b[0m(-0.03107)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.23411 \u001b[0m(-0.02612)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24669 \u001b[0m(-0.01216)\n",
            "     | > avg_loss_0:\u001b[91m 2.94257 \u001b[0m(+0.06281)\n",
            "     | > avg_loss_gen:\u001b[92m 1.46321 \u001b[0m(-0.41168)\n",
            "     | > avg_loss_kl:\u001b[92m 4.95474 \u001b[0m(-0.38232)\n",
            "     | > avg_loss_feat:\u001b[91m 1.68838 \u001b[0m(+0.38742)\n",
            "     | > avg_loss_mel:\u001b[92m 15.26663 \u001b[0m(-0.54947)\n",
            "     | > avg_loss_duration:\u001b[92m 3.36670 \u001b[0m(-0.06766)\n",
            "     | > avg_loss_1:\u001b[92m 26.73966 \u001b[0m(-1.02370)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 618/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:38) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.89822  (2.89822)\n",
            "     | > loss_disc_real_0: 0.32217  (0.32217)\n",
            "     | > loss_disc_real_1: 0.24557  (0.24557)\n",
            "     | > loss_disc_real_2: 0.25422  (0.25422)\n",
            "     | > loss_disc_real_3: 0.23818  (0.23818)\n",
            "     | > loss_disc_real_4: 0.30973  (0.30973)\n",
            "     | > loss_disc_real_5: 0.25965  (0.25965)\n",
            "     | > loss_0: 2.89822  (2.89822)\n",
            "     | > loss_gen: 1.94264  (1.94264)\n",
            "     | > loss_kl: 4.64956  (4.64956)\n",
            "     | > loss_feat: 1.23431  (1.23431)\n",
            "     | > loss_mel: 15.30697  (15.30697)\n",
            "     | > loss_duration: 3.51914  (3.51914)\n",
            "     | > loss_1: 26.65262  (26.65262)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17814 \u001b[0m(-0.00685)\n",
            "     | > avg_loss_disc:\u001b[92m 2.89822 \u001b[0m(-0.04435)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.32217 \u001b[0m(+0.17232)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24557 \u001b[0m(+0.00011)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.25422 \u001b[0m(+0.02006)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.23818 \u001b[0m(+0.02349)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.30973 \u001b[0m(+0.07562)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.25965 \u001b[0m(+0.01296)\n",
            "     | > avg_loss_0:\u001b[92m 2.89822 \u001b[0m(-0.04435)\n",
            "     | > avg_loss_gen:\u001b[91m 1.94264 \u001b[0m(+0.47944)\n",
            "     | > avg_loss_kl:\u001b[92m 4.64956 \u001b[0m(-0.30518)\n",
            "     | > avg_loss_feat:\u001b[92m 1.23431 \u001b[0m(-0.45408)\n",
            "     | > avg_loss_mel:\u001b[91m 15.30697 \u001b[0m(+0.04034)\n",
            "     | > avg_loss_duration:\u001b[91m 3.51914 \u001b[0m(+0.15244)\n",
            "     | > avg_loss_1:\u001b[92m 26.65262 \u001b[0m(-0.08704)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 619/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:44) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.79683  (2.79683)\n",
            "     | > loss_disc_real_0: 0.16099  (0.16099)\n",
            "     | > loss_disc_real_1: 0.22908  (0.22908)\n",
            "     | > loss_disc_real_2: 0.21947  (0.21947)\n",
            "     | > loss_disc_real_3: 0.20827  (0.20827)\n",
            "     | > loss_disc_real_4: 0.17053  (0.17053)\n",
            "     | > loss_disc_real_5: 0.18854  (0.18854)\n",
            "     | > loss_0: 2.79683  (2.79683)\n",
            "     | > loss_gen: 1.64672  (1.64672)\n",
            "     | > loss_kl: 5.29201  (5.29201)\n",
            "     | > loss_feat: 2.20181  (2.20181)\n",
            "     | > loss_mel: 18.15107  (18.15107)\n",
            "     | > loss_duration: 3.45518  (3.45518)\n",
            "     | > loss_1: 30.74680  (30.74680)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17696 \u001b[0m(-0.00118)\n",
            "     | > avg_loss_disc:\u001b[92m 2.79683 \u001b[0m(-0.10139)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.16099 \u001b[0m(-0.16119)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.22908 \u001b[0m(-0.01650)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.21947 \u001b[0m(-0.03476)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.20827 \u001b[0m(-0.02991)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.17053 \u001b[0m(-0.13920)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.18854 \u001b[0m(-0.07111)\n",
            "     | > avg_loss_0:\u001b[92m 2.79683 \u001b[0m(-0.10139)\n",
            "     | > avg_loss_gen:\u001b[92m 1.64672 \u001b[0m(-0.29592)\n",
            "     | > avg_loss_kl:\u001b[91m 5.29201 \u001b[0m(+0.64245)\n",
            "     | > avg_loss_feat:\u001b[91m 2.20181 \u001b[0m(+0.96751)\n",
            "     | > avg_loss_mel:\u001b[91m 18.15107 \u001b[0m(+2.84410)\n",
            "     | > avg_loss_duration:\u001b[92m 3.45518 \u001b[0m(-0.06395)\n",
            "     | > avg_loss_1:\u001b[91m 30.74680 \u001b[0m(+4.09418)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 620/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:50) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.82002  (2.82002)\n",
            "     | > loss_disc_real_0: 0.19019  (0.19019)\n",
            "     | > loss_disc_real_1: 0.21650  (0.21650)\n",
            "     | > loss_disc_real_2: 0.25410  (0.25410)\n",
            "     | > loss_disc_real_3: 0.26154  (0.26154)\n",
            "     | > loss_disc_real_4: 0.29089  (0.29089)\n",
            "     | > loss_disc_real_5: 0.26543  (0.26543)\n",
            "     | > loss_0: 2.82002  (2.82002)\n",
            "     | > loss_gen: 1.68807  (1.68807)\n",
            "     | > loss_kl: 5.38343  (5.38343)\n",
            "     | > loss_feat: 0.77055  (0.77055)\n",
            "     | > loss_mel: 14.55624  (14.55624)\n",
            "     | > loss_duration: 3.59498  (3.59498)\n",
            "     | > loss_1: 25.99326  (25.99326)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18738 \u001b[0m(+0.01042)\n",
            "     | > avg_loss_disc:\u001b[91m 2.82002 \u001b[0m(+0.02319)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.19019 \u001b[0m(+0.02920)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.21650 \u001b[0m(-0.01258)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.25410 \u001b[0m(+0.03463)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26154 \u001b[0m(+0.05327)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.29089 \u001b[0m(+0.12036)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.26543 \u001b[0m(+0.07689)\n",
            "     | > avg_loss_0:\u001b[91m 2.82002 \u001b[0m(+0.02319)\n",
            "     | > avg_loss_gen:\u001b[91m 1.68807 \u001b[0m(+0.04135)\n",
            "     | > avg_loss_kl:\u001b[91m 5.38343 \u001b[0m(+0.09142)\n",
            "     | > avg_loss_feat:\u001b[92m 0.77055 \u001b[0m(-1.43126)\n",
            "     | > avg_loss_mel:\u001b[92m 14.55624 \u001b[0m(-3.59483)\n",
            "     | > avg_loss_duration:\u001b[91m 3.59498 \u001b[0m(+0.13979)\n",
            "     | > avg_loss_1:\u001b[92m 25.99326 \u001b[0m(-4.75354)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 621/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:45:56) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.88935  (2.88935)\n",
            "     | > loss_disc_real_0: 0.42019  (0.42019)\n",
            "     | > loss_disc_real_1: 0.26983  (0.26983)\n",
            "     | > loss_disc_real_2: 0.22222  (0.22222)\n",
            "     | > loss_disc_real_3: 0.29064  (0.29064)\n",
            "     | > loss_disc_real_4: 0.23463  (0.23463)\n",
            "     | > loss_disc_real_5: 0.20430  (0.20430)\n",
            "     | > loss_0: 2.88935  (2.88935)\n",
            "     | > loss_gen: 1.94155  (1.94155)\n",
            "     | > loss_kl: 4.99566  (4.99566)\n",
            "     | > loss_feat: 1.50761  (1.50761)\n",
            "     | > loss_mel: 18.16575  (18.16575)\n",
            "     | > loss_duration: 3.62793  (3.62793)\n",
            "     | > loss_1: 30.23850  (30.23850)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18045 \u001b[0m(-0.00693)\n",
            "     | > avg_loss_disc:\u001b[91m 2.88935 \u001b[0m(+0.06934)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.42019 \u001b[0m(+0.23001)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.26983 \u001b[0m(+0.05334)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.22222 \u001b[0m(-0.03188)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.29064 \u001b[0m(+0.02910)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.23463 \u001b[0m(-0.05627)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.20430 \u001b[0m(-0.06113)\n",
            "     | > avg_loss_0:\u001b[91m 2.88935 \u001b[0m(+0.06934)\n",
            "     | > avg_loss_gen:\u001b[91m 1.94155 \u001b[0m(+0.25348)\n",
            "     | > avg_loss_kl:\u001b[92m 4.99566 \u001b[0m(-0.38776)\n",
            "     | > avg_loss_feat:\u001b[91m 1.50761 \u001b[0m(+0.73706)\n",
            "     | > avg_loss_mel:\u001b[91m 18.16575 \u001b[0m(+3.60951)\n",
            "     | > avg_loss_duration:\u001b[91m 3.62793 \u001b[0m(+0.03296)\n",
            "     | > avg_loss_1:\u001b[91m 30.23850 \u001b[0m(+4.24524)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 622/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:03) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.12197  (3.12197)\n",
            "     | > loss_disc_real_0: 0.06183  (0.06183)\n",
            "     | > loss_disc_real_1: 0.22732  (0.22732)\n",
            "     | > loss_disc_real_2: 0.23655  (0.23655)\n",
            "     | > loss_disc_real_3: 0.24549  (0.24549)\n",
            "     | > loss_disc_real_4: 0.24922  (0.24922)\n",
            "     | > loss_disc_real_5: 0.25953  (0.25953)\n",
            "     | > loss_0: 3.12197  (3.12197)\n",
            "     | > loss_gen: 1.29754  (1.29754)\n",
            "     | > loss_kl: 5.36867  (5.36867)\n",
            "     | > loss_feat: 0.37077  (0.37077)\n",
            "     | > loss_mel: 13.11727  (13.11727)\n",
            "     | > loss_duration: 3.51342  (3.51342)\n",
            "     | > loss_1: 23.66767  (23.66767)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18812 \u001b[0m(+0.00767)\n",
            "     | > avg_loss_disc:\u001b[91m 3.12197 \u001b[0m(+0.23261)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.06183 \u001b[0m(-0.35837)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.22732 \u001b[0m(-0.04251)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.23655 \u001b[0m(+0.01433)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24549 \u001b[0m(-0.04515)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.24922 \u001b[0m(+0.01459)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.25953 \u001b[0m(+0.05523)\n",
            "     | > avg_loss_0:\u001b[91m 3.12197 \u001b[0m(+0.23261)\n",
            "     | > avg_loss_gen:\u001b[92m 1.29754 \u001b[0m(-0.64400)\n",
            "     | > avg_loss_kl:\u001b[91m 5.36867 \u001b[0m(+0.37301)\n",
            "     | > avg_loss_feat:\u001b[92m 0.37077 \u001b[0m(-1.13685)\n",
            "     | > avg_loss_mel:\u001b[92m 13.11727 \u001b[0m(-5.04848)\n",
            "     | > avg_loss_duration:\u001b[92m 3.51342 \u001b[0m(-0.11452)\n",
            "     | > avg_loss_1:\u001b[92m 23.66767 \u001b[0m(-6.57083)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 623/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:09) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.96026  (2.96026)\n",
            "     | > loss_disc_real_0: 0.24703  (0.24703)\n",
            "     | > loss_disc_real_1: 0.30910  (0.30910)\n",
            "     | > loss_disc_real_2: 0.27438  (0.27438)\n",
            "     | > loss_disc_real_3: 0.21857  (0.21857)\n",
            "     | > loss_disc_real_4: 0.29275  (0.29275)\n",
            "     | > loss_disc_real_5: 0.25553  (0.25553)\n",
            "     | > loss_0: 2.96026  (2.96026)\n",
            "     | > loss_gen: 1.68866  (1.68866)\n",
            "     | > loss_kl: 5.05968  (5.05968)\n",
            "     | > loss_feat: 0.75068  (0.75068)\n",
            "     | > loss_mel: 14.67424  (14.67424)\n",
            "     | > loss_duration: 3.46339  (3.46339)\n",
            "     | > loss_1: 25.63665  (25.63665)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19786 \u001b[0m(+0.00973)\n",
            "     | > avg_loss_disc:\u001b[92m 2.96026 \u001b[0m(-0.16170)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.24703 \u001b[0m(+0.18520)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.30910 \u001b[0m(+0.08178)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27438 \u001b[0m(+0.03783)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21857 \u001b[0m(-0.02693)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.29275 \u001b[0m(+0.04354)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.25553 \u001b[0m(-0.00399)\n",
            "     | > avg_loss_0:\u001b[92m 2.96026 \u001b[0m(-0.16170)\n",
            "     | > avg_loss_gen:\u001b[91m 1.68866 \u001b[0m(+0.39112)\n",
            "     | > avg_loss_kl:\u001b[92m 5.05968 \u001b[0m(-0.30899)\n",
            "     | > avg_loss_feat:\u001b[91m 0.75068 \u001b[0m(+0.37991)\n",
            "     | > avg_loss_mel:\u001b[91m 14.67424 \u001b[0m(+1.55697)\n",
            "     | > avg_loss_duration:\u001b[92m 3.46339 \u001b[0m(-0.05003)\n",
            "     | > avg_loss_1:\u001b[91m 25.63665 \u001b[0m(+1.96898)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 624/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:16) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 2/3 -- GLOBAL_STEP: 1001875\u001b[0m\n",
            "     | > loss_disc: 2.83142  (2.91688)\n",
            "     | > loss_disc_real_0: 0.22806  (0.27295)\n",
            "     | > loss_disc_real_1: 0.33336  (0.34809)\n",
            "     | > loss_disc_real_2: 0.28826  (0.30402)\n",
            "     | > loss_disc_real_3: 0.29487  (0.29893)\n",
            "     | > loss_disc_real_4: 0.31183  (0.31422)\n",
            "     | > loss_disc_real_5: 0.29678  (0.31066)\n",
            "     | > loss_0: 2.83142  (2.91688)\n",
            "     | > grad_norm_0: 10.08276  (9.63744)\n",
            "     | > loss_gen: 1.89027  (2.00346)\n",
            "     | > loss_kl: 1.11408  (1.10667)\n",
            "     | > loss_feat: 1.19619  (1.02941)\n",
            "     | > loss_mel: 14.25638  (14.21016)\n",
            "     | > loss_duration: 1.43502  (1.42859)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 19.89194  (19.77829)\n",
            "     | > grad_norm_1: 98.36314  (79.91570)\n",
            "     | > current_lr_0: 0.00018 \n",
            "     | > current_lr_1: 0.00018 \n",
            "     | > step_time: 0.54600  (0.58330)\n",
            "     | > loader_time: 0.01430  (0.09178)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.92666  (2.92666)\n",
            "     | > loss_disc_real_0: 0.23913  (0.23913)\n",
            "     | > loss_disc_real_1: 0.26885  (0.26885)\n",
            "     | > loss_disc_real_2: 0.27448  (0.27448)\n",
            "     | > loss_disc_real_3: 0.28171  (0.28171)\n",
            "     | > loss_disc_real_4: 0.25491  (0.25491)\n",
            "     | > loss_disc_real_5: 0.31821  (0.31821)\n",
            "     | > loss_0: 2.92666  (2.92666)\n",
            "     | > loss_gen: 1.78750  (1.78750)\n",
            "     | > loss_kl: 5.13951  (5.13951)\n",
            "     | > loss_feat: 0.88485  (0.88485)\n",
            "     | > loss_mel: 15.67196  (15.67196)\n",
            "     | > loss_duration: 3.30300  (3.30300)\n",
            "     | > loss_1: 26.78682  (26.78682)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18629 \u001b[0m(-0.01156)\n",
            "     | > avg_loss_disc:\u001b[92m 2.92666 \u001b[0m(-0.03361)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.23913 \u001b[0m(-0.00789)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.26885 \u001b[0m(-0.04025)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27448 \u001b[0m(+0.00010)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.28171 \u001b[0m(+0.06314)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25491 \u001b[0m(-0.03784)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.31821 \u001b[0m(+0.06268)\n",
            "     | > avg_loss_0:\u001b[92m 2.92666 \u001b[0m(-0.03361)\n",
            "     | > avg_loss_gen:\u001b[91m 1.78750 \u001b[0m(+0.09884)\n",
            "     | > avg_loss_kl:\u001b[91m 5.13951 \u001b[0m(+0.07983)\n",
            "     | > avg_loss_feat:\u001b[91m 0.88485 \u001b[0m(+0.13417)\n",
            "     | > avg_loss_mel:\u001b[91m 15.67196 \u001b[0m(+0.99772)\n",
            "     | > avg_loss_duration:\u001b[92m 3.30300 \u001b[0m(-0.16039)\n",
            "     | > avg_loss_1:\u001b[91m 26.78682 \u001b[0m(+1.15017)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 625/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:23) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.67392  (2.67392)\n",
            "     | > loss_disc_real_0: 0.21673  (0.21673)\n",
            "     | > loss_disc_real_1: 0.20894  (0.20894)\n",
            "     | > loss_disc_real_2: 0.23003  (0.23003)\n",
            "     | > loss_disc_real_3: 0.22279  (0.22279)\n",
            "     | > loss_disc_real_4: 0.24289  (0.24289)\n",
            "     | > loss_disc_real_5: 0.24544  (0.24544)\n",
            "     | > loss_0: 2.67392  (2.67392)\n",
            "     | > loss_gen: 1.80353  (1.80353)\n",
            "     | > loss_kl: 5.03251  (5.03251)\n",
            "     | > loss_feat: 1.72156  (1.72156)\n",
            "     | > loss_mel: 16.16052  (16.16052)\n",
            "     | > loss_duration: 3.40633  (3.40633)\n",
            "     | > loss_1: 28.12445  (28.12445)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18401 \u001b[0m(-0.00228)\n",
            "     | > avg_loss_disc:\u001b[92m 2.67392 \u001b[0m(-0.25274)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.21673 \u001b[0m(-0.02240)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20894 \u001b[0m(-0.05991)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.23003 \u001b[0m(-0.04445)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22279 \u001b[0m(-0.05892)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24289 \u001b[0m(-0.01202)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24544 \u001b[0m(-0.07277)\n",
            "     | > avg_loss_0:\u001b[92m 2.67392 \u001b[0m(-0.25274)\n",
            "     | > avg_loss_gen:\u001b[91m 1.80353 \u001b[0m(+0.01603)\n",
            "     | > avg_loss_kl:\u001b[92m 5.03251 \u001b[0m(-0.10700)\n",
            "     | > avg_loss_feat:\u001b[91m 1.72156 \u001b[0m(+0.83671)\n",
            "     | > avg_loss_mel:\u001b[91m 16.16052 \u001b[0m(+0.48856)\n",
            "     | > avg_loss_duration:\u001b[91m 3.40633 \u001b[0m(+0.10333)\n",
            "     | > avg_loss_1:\u001b[91m 28.12445 \u001b[0m(+1.33763)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 626/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:29) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.81361  (2.81361)\n",
            "     | > loss_disc_real_0: 0.25303  (0.25303)\n",
            "     | > loss_disc_real_1: 0.24552  (0.24552)\n",
            "     | > loss_disc_real_2: 0.22569  (0.22569)\n",
            "     | > loss_disc_real_3: 0.17562  (0.17562)\n",
            "     | > loss_disc_real_4: 0.25030  (0.25030)\n",
            "     | > loss_disc_real_5: 0.19577  (0.19577)\n",
            "     | > loss_0: 2.81361  (2.81361)\n",
            "     | > loss_gen: 1.58169  (1.58169)\n",
            "     | > loss_kl: 4.25153  (4.25153)\n",
            "     | > loss_feat: 1.76003  (1.76003)\n",
            "     | > loss_mel: 16.50640  (16.50640)\n",
            "     | > loss_duration: 3.37445  (3.37445)\n",
            "     | > loss_1: 27.47410  (27.47410)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18898 \u001b[0m(+0.00497)\n",
            "     | > avg_loss_disc:\u001b[91m 2.81361 \u001b[0m(+0.13969)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.25303 \u001b[0m(+0.03630)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.24552 \u001b[0m(+0.03658)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.22569 \u001b[0m(-0.00434)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.17562 \u001b[0m(-0.04718)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.25030 \u001b[0m(+0.00741)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.19577 \u001b[0m(-0.04967)\n",
            "     | > avg_loss_0:\u001b[91m 2.81361 \u001b[0m(+0.13969)\n",
            "     | > avg_loss_gen:\u001b[92m 1.58169 \u001b[0m(-0.22184)\n",
            "     | > avg_loss_kl:\u001b[92m 4.25153 \u001b[0m(-0.78098)\n",
            "     | > avg_loss_feat:\u001b[91m 1.76003 \u001b[0m(+0.03847)\n",
            "     | > avg_loss_mel:\u001b[91m 16.50640 \u001b[0m(+0.34587)\n",
            "     | > avg_loss_duration:\u001b[92m 3.37445 \u001b[0m(-0.03187)\n",
            "     | > avg_loss_1:\u001b[92m 27.47410 \u001b[0m(-0.65035)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 627/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:35) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.87182  (2.87182)\n",
            "     | > loss_disc_real_0: 0.15859  (0.15859)\n",
            "     | > loss_disc_real_1: 0.25440  (0.25440)\n",
            "     | > loss_disc_real_2: 0.26297  (0.26297)\n",
            "     | > loss_disc_real_3: 0.25869  (0.25869)\n",
            "     | > loss_disc_real_4: 0.29406  (0.29406)\n",
            "     | > loss_disc_real_5: 0.31395  (0.31395)\n",
            "     | > loss_0: 2.87182  (2.87182)\n",
            "     | > loss_gen: 1.70666  (1.70666)\n",
            "     | > loss_kl: 5.07283  (5.07283)\n",
            "     | > loss_feat: 0.74568  (0.74568)\n",
            "     | > loss_mel: 14.29387  (14.29387)\n",
            "     | > loss_duration: 3.66283  (3.66283)\n",
            "     | > loss_1: 25.48187  (25.48187)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18769 \u001b[0m(-0.00129)\n",
            "     | > avg_loss_disc:\u001b[91m 2.87182 \u001b[0m(+0.05822)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.15859 \u001b[0m(-0.09444)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.25440 \u001b[0m(+0.00888)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26297 \u001b[0m(+0.03727)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.25869 \u001b[0m(+0.08308)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.29406 \u001b[0m(+0.04375)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.31395 \u001b[0m(+0.11818)\n",
            "     | > avg_loss_0:\u001b[91m 2.87182 \u001b[0m(+0.05822)\n",
            "     | > avg_loss_gen:\u001b[91m 1.70666 \u001b[0m(+0.12496)\n",
            "     | > avg_loss_kl:\u001b[91m 5.07283 \u001b[0m(+0.82130)\n",
            "     | > avg_loss_feat:\u001b[92m 0.74568 \u001b[0m(-1.01435)\n",
            "     | > avg_loss_mel:\u001b[92m 14.29387 \u001b[0m(-2.21253)\n",
            "     | > avg_loss_duration:\u001b[91m 3.66283 \u001b[0m(+0.28837)\n",
            "     | > avg_loss_1:\u001b[92m 25.48187 \u001b[0m(-1.99223)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 628/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:42) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.82324  (2.82324)\n",
            "     | > loss_disc_real_0: 0.24509  (0.24509)\n",
            "     | > loss_disc_real_1: 0.23872  (0.23872)\n",
            "     | > loss_disc_real_2: 0.22979  (0.22979)\n",
            "     | > loss_disc_real_3: 0.25425  (0.25425)\n",
            "     | > loss_disc_real_4: 0.25102  (0.25102)\n",
            "     | > loss_disc_real_5: 0.24625  (0.24625)\n",
            "     | > loss_0: 2.82324  (2.82324)\n",
            "     | > loss_gen: 1.73238  (1.73238)\n",
            "     | > loss_kl: 5.01176  (5.01176)\n",
            "     | > loss_feat: 0.72736  (0.72736)\n",
            "     | > loss_mel: 13.42310  (13.42310)\n",
            "     | > loss_duration: 3.49199  (3.49199)\n",
            "     | > loss_1: 24.38658  (24.38658)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18268 \u001b[0m(-0.00501)\n",
            "     | > avg_loss_disc:\u001b[92m 2.82324 \u001b[0m(-0.04858)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.24509 \u001b[0m(+0.08650)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.23872 \u001b[0m(-0.01568)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.22979 \u001b[0m(-0.03318)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.25425 \u001b[0m(-0.00444)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25102 \u001b[0m(-0.04303)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24625 \u001b[0m(-0.06771)\n",
            "     | > avg_loss_0:\u001b[92m 2.82324 \u001b[0m(-0.04858)\n",
            "     | > avg_loss_gen:\u001b[91m 1.73238 \u001b[0m(+0.02572)\n",
            "     | > avg_loss_kl:\u001b[92m 5.01176 \u001b[0m(-0.06107)\n",
            "     | > avg_loss_feat:\u001b[92m 0.72736 \u001b[0m(-0.01833)\n",
            "     | > avg_loss_mel:\u001b[92m 13.42310 \u001b[0m(-0.87077)\n",
            "     | > avg_loss_duration:\u001b[92m 3.49199 \u001b[0m(-0.17084)\n",
            "     | > avg_loss_1:\u001b[92m 24.38658 \u001b[0m(-1.09529)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 629/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:48) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.76650  (2.76650)\n",
            "     | > loss_disc_real_0: 0.11865  (0.11865)\n",
            "     | > loss_disc_real_1: 0.25638  (0.25638)\n",
            "     | > loss_disc_real_2: 0.26371  (0.26371)\n",
            "     | > loss_disc_real_3: 0.21543  (0.21543)\n",
            "     | > loss_disc_real_4: 0.24126  (0.24126)\n",
            "     | > loss_disc_real_5: 0.21788  (0.21788)\n",
            "     | > loss_0: 2.76650  (2.76650)\n",
            "     | > loss_gen: 1.62457  (1.62457)\n",
            "     | > loss_kl: 4.69756  (4.69756)\n",
            "     | > loss_feat: 1.32341  (1.32341)\n",
            "     | > loss_mel: 17.12172  (17.12172)\n",
            "     | > loss_duration: 3.42326  (3.42326)\n",
            "     | > loss_1: 28.19052  (28.19052)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17860 \u001b[0m(-0.00408)\n",
            "     | > avg_loss_disc:\u001b[92m 2.76650 \u001b[0m(-0.05674)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.11865 \u001b[0m(-0.12644)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.25638 \u001b[0m(+0.01766)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26371 \u001b[0m(+0.03393)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.21543 \u001b[0m(-0.03882)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24126 \u001b[0m(-0.00977)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.21788 \u001b[0m(-0.02836)\n",
            "     | > avg_loss_0:\u001b[92m 2.76650 \u001b[0m(-0.05674)\n",
            "     | > avg_loss_gen:\u001b[92m 1.62457 \u001b[0m(-0.10781)\n",
            "     | > avg_loss_kl:\u001b[92m 4.69756 \u001b[0m(-0.31420)\n",
            "     | > avg_loss_feat:\u001b[91m 1.32341 \u001b[0m(+0.59605)\n",
            "     | > avg_loss_mel:\u001b[91m 17.12172 \u001b[0m(+3.69862)\n",
            "     | > avg_loss_duration:\u001b[92m 3.42326 \u001b[0m(-0.06872)\n",
            "     | > avg_loss_1:\u001b[91m 28.19052 \u001b[0m(+3.80394)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 630/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:46:54) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.01190  (3.01190)\n",
            "     | > loss_disc_real_0: 0.31798  (0.31798)\n",
            "     | > loss_disc_real_1: 0.23763  (0.23763)\n",
            "     | > loss_disc_real_2: 0.28034  (0.28034)\n",
            "     | > loss_disc_real_3: 0.26947  (0.26947)\n",
            "     | > loss_disc_real_4: 0.26344  (0.26344)\n",
            "     | > loss_disc_real_5: 0.29340  (0.29340)\n",
            "     | > loss_0: 3.01190  (3.01190)\n",
            "     | > loss_gen: 1.74101  (1.74101)\n",
            "     | > loss_kl: 5.11526  (5.11526)\n",
            "     | > loss_feat: 1.11201  (1.11201)\n",
            "     | > loss_mel: 15.76756  (15.76756)\n",
            "     | > loss_duration: 3.31196  (3.31196)\n",
            "     | > loss_1: 27.04780  (27.04780)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18071 \u001b[0m(+0.00210)\n",
            "     | > avg_loss_disc:\u001b[91m 3.01190 \u001b[0m(+0.24540)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.31798 \u001b[0m(+0.19933)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.23763 \u001b[0m(-0.01875)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.28034 \u001b[0m(+0.01663)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26947 \u001b[0m(+0.05404)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.26344 \u001b[0m(+0.02219)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.29340 \u001b[0m(+0.07551)\n",
            "     | > avg_loss_0:\u001b[91m 3.01190 \u001b[0m(+0.24540)\n",
            "     | > avg_loss_gen:\u001b[91m 1.74101 \u001b[0m(+0.11644)\n",
            "     | > avg_loss_kl:\u001b[91m 5.11526 \u001b[0m(+0.41770)\n",
            "     | > avg_loss_feat:\u001b[92m 1.11201 \u001b[0m(-0.21140)\n",
            "     | > avg_loss_mel:\u001b[92m 15.76756 \u001b[0m(-1.35416)\n",
            "     | > avg_loss_duration:\u001b[92m 3.31196 \u001b[0m(-0.11131)\n",
            "     | > avg_loss_1:\u001b[92m 27.04780 \u001b[0m(-1.14272)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 631/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:01) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.74903  (2.74903)\n",
            "     | > loss_disc_real_0: 0.23398  (0.23398)\n",
            "     | > loss_disc_real_1: 0.27688  (0.27688)\n",
            "     | > loss_disc_real_2: 0.24033  (0.24033)\n",
            "     | > loss_disc_real_3: 0.31919  (0.31919)\n",
            "     | > loss_disc_real_4: 0.24972  (0.24972)\n",
            "     | > loss_disc_real_5: 0.29300  (0.29300)\n",
            "     | > loss_0: 2.74903  (2.74903)\n",
            "     | > loss_gen: 2.09143  (2.09143)\n",
            "     | > loss_kl: 4.92108  (4.92108)\n",
            "     | > loss_feat: 1.65093  (1.65093)\n",
            "     | > loss_mel: 16.98333  (16.98333)\n",
            "     | > loss_duration: 3.47755  (3.47755)\n",
            "     | > loss_1: 29.12432  (29.12432)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17891 \u001b[0m(-0.00180)\n",
            "     | > avg_loss_disc:\u001b[92m 2.74903 \u001b[0m(-0.26287)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.23398 \u001b[0m(-0.08400)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.27688 \u001b[0m(+0.03925)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.24033 \u001b[0m(-0.04001)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.31919 \u001b[0m(+0.04972)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24972 \u001b[0m(-0.01372)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.29300 \u001b[0m(-0.00039)\n",
            "     | > avg_loss_0:\u001b[92m 2.74903 \u001b[0m(-0.26287)\n",
            "     | > avg_loss_gen:\u001b[91m 2.09143 \u001b[0m(+0.35041)\n",
            "     | > avg_loss_kl:\u001b[92m 4.92108 \u001b[0m(-0.19418)\n",
            "     | > avg_loss_feat:\u001b[91m 1.65093 \u001b[0m(+0.53892)\n",
            "     | > avg_loss_mel:\u001b[91m 16.98333 \u001b[0m(+1.21577)\n",
            "     | > avg_loss_duration:\u001b[91m 3.47755 \u001b[0m(+0.16559)\n",
            "     | > avg_loss_1:\u001b[91m 29.12432 \u001b[0m(+2.07652)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 632/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:07) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.98760  (2.98760)\n",
            "     | > loss_disc_real_0: 0.18192  (0.18192)\n",
            "     | > loss_disc_real_1: 0.24865  (0.24865)\n",
            "     | > loss_disc_real_2: 0.26059  (0.26059)\n",
            "     | > loss_disc_real_3: 0.22776  (0.22776)\n",
            "     | > loss_disc_real_4: 0.24047  (0.24047)\n",
            "     | > loss_disc_real_5: 0.24648  (0.24648)\n",
            "     | > loss_0: 2.98760  (2.98760)\n",
            "     | > loss_gen: 1.43475  (1.43475)\n",
            "     | > loss_kl: 5.33081  (5.33081)\n",
            "     | > loss_feat: 0.57423  (0.57423)\n",
            "     | > loss_mel: 13.30440  (13.30440)\n",
            "     | > loss_duration: 3.53457  (3.53457)\n",
            "     | > loss_1: 24.17876  (24.17876)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18002 \u001b[0m(+0.00111)\n",
            "     | > avg_loss_disc:\u001b[91m 2.98760 \u001b[0m(+0.23858)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.18192 \u001b[0m(-0.05206)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.24865 \u001b[0m(-0.02823)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26059 \u001b[0m(+0.02026)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22776 \u001b[0m(-0.09143)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24047 \u001b[0m(-0.00925)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24648 \u001b[0m(-0.04652)\n",
            "     | > avg_loss_0:\u001b[91m 2.98760 \u001b[0m(+0.23858)\n",
            "     | > avg_loss_gen:\u001b[92m 1.43475 \u001b[0m(-0.65668)\n",
            "     | > avg_loss_kl:\u001b[91m 5.33081 \u001b[0m(+0.40973)\n",
            "     | > avg_loss_feat:\u001b[92m 0.57423 \u001b[0m(-1.07670)\n",
            "     | > avg_loss_mel:\u001b[92m 13.30440 \u001b[0m(-3.67892)\n",
            "     | > avg_loss_duration:\u001b[91m 3.53457 \u001b[0m(+0.05702)\n",
            "     | > avg_loss_1:\u001b[92m 24.17876 \u001b[0m(-4.94556)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 633/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:13) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0/3 -- GLOBAL_STEP: 1001900\u001b[0m\n",
            "     | > loss_disc: 2.89759  (2.89759)\n",
            "     | > loss_disc_real_0: 0.14533  (0.14533)\n",
            "     | > loss_disc_real_1: 0.24239  (0.24239)\n",
            "     | > loss_disc_real_2: 0.24242  (0.24242)\n",
            "     | > loss_disc_real_3: 0.25139  (0.25139)\n",
            "     | > loss_disc_real_4: 0.22341  (0.22341)\n",
            "     | > loss_disc_real_5: 0.19921  (0.19921)\n",
            "     | > loss_0: 2.89759  (2.89759)\n",
            "     | > grad_norm_0: 5.66374  (5.66374)\n",
            "     | > loss_gen: 1.59828  (1.59828)\n",
            "     | > loss_kl: 0.97658  (0.97658)\n",
            "     | > loss_feat: 1.48847  (1.48847)\n",
            "     | > loss_mel: 15.11246  (15.11246)\n",
            "     | > loss_duration: 1.40422  (1.40422)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 20.58001  (20.58001)\n",
            "     | > grad_norm_1: 73.99376  (73.99376)\n",
            "     | > current_lr_0: 0.00018 \n",
            "     | > current_lr_1: 0.00018 \n",
            "     | > step_time: 0.57890  (0.57892)\n",
            "     | > loader_time: 0.02380  (0.02377)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.70804  (2.70804)\n",
            "     | > loss_disc_real_0: 0.19262  (0.19262)\n",
            "     | > loss_disc_real_1: 0.26041  (0.26041)\n",
            "     | > loss_disc_real_2: 0.25643  (0.25643)\n",
            "     | > loss_disc_real_3: 0.22644  (0.22644)\n",
            "     | > loss_disc_real_4: 0.26193  (0.26193)\n",
            "     | > loss_disc_real_5: 0.22272  (0.22272)\n",
            "     | > loss_0: 2.70804  (2.70804)\n",
            "     | > loss_gen: 1.79945  (1.79945)\n",
            "     | > loss_kl: 5.14592  (5.14592)\n",
            "     | > loss_feat: 1.41889  (1.41889)\n",
            "     | > loss_mel: 15.17598  (15.17598)\n",
            "     | > loss_duration: 3.60560  (3.60560)\n",
            "     | > loss_1: 27.14584  (27.14584)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18258 \u001b[0m(+0.00256)\n",
            "     | > avg_loss_disc:\u001b[92m 2.70804 \u001b[0m(-0.27956)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.19262 \u001b[0m(+0.01070)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.26041 \u001b[0m(+0.01176)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.25643 \u001b[0m(-0.00416)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22644 \u001b[0m(-0.00132)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.26193 \u001b[0m(+0.02146)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22272 \u001b[0m(-0.02376)\n",
            "     | > avg_loss_0:\u001b[92m 2.70804 \u001b[0m(-0.27956)\n",
            "     | > avg_loss_gen:\u001b[91m 1.79945 \u001b[0m(+0.36471)\n",
            "     | > avg_loss_kl:\u001b[92m 5.14592 \u001b[0m(-0.18489)\n",
            "     | > avg_loss_feat:\u001b[91m 1.41889 \u001b[0m(+0.84466)\n",
            "     | > avg_loss_mel:\u001b[91m 15.17598 \u001b[0m(+1.87157)\n",
            "     | > avg_loss_duration:\u001b[91m 3.60560 \u001b[0m(+0.07103)\n",
            "     | > avg_loss_1:\u001b[91m 27.14584 \u001b[0m(+2.96708)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 634/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:19) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.77487  (2.77487)\n",
            "     | > loss_disc_real_0: 0.17639  (0.17639)\n",
            "     | > loss_disc_real_1: 0.25730  (0.25730)\n",
            "     | > loss_disc_real_2: 0.26569  (0.26569)\n",
            "     | > loss_disc_real_3: 0.26397  (0.26397)\n",
            "     | > loss_disc_real_4: 0.24677  (0.24677)\n",
            "     | > loss_disc_real_5: 0.29856  (0.29856)\n",
            "     | > loss_0: 2.77487  (2.77487)\n",
            "     | > loss_gen: 1.92607  (1.92607)\n",
            "     | > loss_kl: 5.11223  (5.11223)\n",
            "     | > loss_feat: 1.76589  (1.76589)\n",
            "     | > loss_mel: 16.31096  (16.31096)\n",
            "     | > loss_duration: 3.65635  (3.65635)\n",
            "     | > loss_1: 28.77150  (28.77150)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18363 \u001b[0m(+0.00105)\n",
            "     | > avg_loss_disc:\u001b[91m 2.77487 \u001b[0m(+0.06682)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.17639 \u001b[0m(-0.01624)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.25730 \u001b[0m(-0.00312)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26569 \u001b[0m(+0.00926)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26397 \u001b[0m(+0.03753)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24677 \u001b[0m(-0.01516)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.29856 \u001b[0m(+0.07584)\n",
            "     | > avg_loss_0:\u001b[91m 2.77487 \u001b[0m(+0.06682)\n",
            "     | > avg_loss_gen:\u001b[91m 1.92607 \u001b[0m(+0.12661)\n",
            "     | > avg_loss_kl:\u001b[92m 5.11223 \u001b[0m(-0.03369)\n",
            "     | > avg_loss_feat:\u001b[91m 1.76589 \u001b[0m(+0.34700)\n",
            "     | > avg_loss_mel:\u001b[91m 16.31096 \u001b[0m(+1.13498)\n",
            "     | > avg_loss_duration:\u001b[91m 3.65635 \u001b[0m(+0.05075)\n",
            "     | > avg_loss_1:\u001b[91m 28.77150 \u001b[0m(+1.62566)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 635/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:25) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.53317  (2.53317)\n",
            "     | > loss_disc_real_0: 0.10997  (0.10997)\n",
            "     | > loss_disc_real_1: 0.19229  (0.19229)\n",
            "     | > loss_disc_real_2: 0.20216  (0.20216)\n",
            "     | > loss_disc_real_3: 0.24983  (0.24983)\n",
            "     | > loss_disc_real_4: 0.20765  (0.20765)\n",
            "     | > loss_disc_real_5: 0.22369  (0.22369)\n",
            "     | > loss_0: 2.53317  (2.53317)\n",
            "     | > loss_gen: 1.89874  (1.89874)\n",
            "     | > loss_kl: 4.92431  (4.92431)\n",
            "     | > loss_feat: 2.86127  (2.86127)\n",
            "     | > loss_mel: 17.91466  (17.91466)\n",
            "     | > loss_duration: 3.52717  (3.52717)\n",
            "     | > loss_1: 31.12615  (31.12615)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18518 \u001b[0m(+0.00155)\n",
            "     | > avg_loss_disc:\u001b[92m 2.53317 \u001b[0m(-0.24170)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.10997 \u001b[0m(-0.06641)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.19229 \u001b[0m(-0.06501)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.20216 \u001b[0m(-0.06353)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24983 \u001b[0m(-0.01414)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20765 \u001b[0m(-0.03912)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22369 \u001b[0m(-0.07487)\n",
            "     | > avg_loss_0:\u001b[92m 2.53317 \u001b[0m(-0.24170)\n",
            "     | > avg_loss_gen:\u001b[92m 1.89874 \u001b[0m(-0.02732)\n",
            "     | > avg_loss_kl:\u001b[92m 4.92431 \u001b[0m(-0.18792)\n",
            "     | > avg_loss_feat:\u001b[91m 2.86127 \u001b[0m(+1.09538)\n",
            "     | > avg_loss_mel:\u001b[91m 17.91466 \u001b[0m(+1.60370)\n",
            "     | > avg_loss_duration:\u001b[92m 3.52717 \u001b[0m(-0.12918)\n",
            "     | > avg_loss_1:\u001b[91m 31.12615 \u001b[0m(+2.35465)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 636/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:32) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.91121  (2.91121)\n",
            "     | > loss_disc_real_0: 0.25898  (0.25898)\n",
            "     | > loss_disc_real_1: 0.25255  (0.25255)\n",
            "     | > loss_disc_real_2: 0.26291  (0.26291)\n",
            "     | > loss_disc_real_3: 0.26124  (0.26124)\n",
            "     | > loss_disc_real_4: 0.26446  (0.26446)\n",
            "     | > loss_disc_real_5: 0.21865  (0.21865)\n",
            "     | > loss_0: 2.91121  (2.91121)\n",
            "     | > loss_gen: 1.67182  (1.67182)\n",
            "     | > loss_kl: 5.17553  (5.17553)\n",
            "     | > loss_feat: 1.07408  (1.07408)\n",
            "     | > loss_mel: 17.14624  (17.14624)\n",
            "     | > loss_duration: 3.54166  (3.54166)\n",
            "     | > loss_1: 28.60933  (28.60933)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18170 \u001b[0m(-0.00348)\n",
            "     | > avg_loss_disc:\u001b[91m 2.91121 \u001b[0m(+0.37804)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.25898 \u001b[0m(+0.14900)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.25255 \u001b[0m(+0.06026)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26291 \u001b[0m(+0.06075)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26124 \u001b[0m(+0.01142)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.26446 \u001b[0m(+0.05682)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.21865 \u001b[0m(-0.00504)\n",
            "     | > avg_loss_0:\u001b[91m 2.91121 \u001b[0m(+0.37804)\n",
            "     | > avg_loss_gen:\u001b[92m 1.67182 \u001b[0m(-0.22693)\n",
            "     | > avg_loss_kl:\u001b[91m 5.17553 \u001b[0m(+0.25122)\n",
            "     | > avg_loss_feat:\u001b[92m 1.07408 \u001b[0m(-1.78719)\n",
            "     | > avg_loss_mel:\u001b[92m 17.14624 \u001b[0m(-0.76842)\n",
            "     | > avg_loss_duration:\u001b[91m 3.54166 \u001b[0m(+0.01449)\n",
            "     | > avg_loss_1:\u001b[92m 28.60933 \u001b[0m(-2.51682)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 637/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:38) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.73762  (2.73762)\n",
            "     | > loss_disc_real_0: 0.25177  (0.25177)\n",
            "     | > loss_disc_real_1: 0.19506  (0.19506)\n",
            "     | > loss_disc_real_2: 0.18788  (0.18788)\n",
            "     | > loss_disc_real_3: 0.20293  (0.20293)\n",
            "     | > loss_disc_real_4: 0.21774  (0.21774)\n",
            "     | > loss_disc_real_5: 0.22856  (0.22856)\n",
            "     | > loss_0: 2.73762  (2.73762)\n",
            "     | > loss_gen: 1.68261  (1.68261)\n",
            "     | > loss_kl: 5.11345  (5.11345)\n",
            "     | > loss_feat: 1.55062  (1.55062)\n",
            "     | > loss_mel: 16.86305  (16.86305)\n",
            "     | > loss_duration: 3.51139  (3.51139)\n",
            "     | > loss_1: 28.72111  (28.72111)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18180 \u001b[0m(+0.00010)\n",
            "     | > avg_loss_disc:\u001b[92m 2.73762 \u001b[0m(-0.17359)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.25177 \u001b[0m(-0.00720)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.19506 \u001b[0m(-0.05749)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.18788 \u001b[0m(-0.07503)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.20293 \u001b[0m(-0.05832)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.21774 \u001b[0m(-0.04672)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.22856 \u001b[0m(+0.00991)\n",
            "     | > avg_loss_0:\u001b[92m 2.73762 \u001b[0m(-0.17359)\n",
            "     | > avg_loss_gen:\u001b[91m 1.68261 \u001b[0m(+0.01079)\n",
            "     | > avg_loss_kl:\u001b[92m 5.11345 \u001b[0m(-0.06208)\n",
            "     | > avg_loss_feat:\u001b[91m 1.55062 \u001b[0m(+0.47654)\n",
            "     | > avg_loss_mel:\u001b[92m 16.86305 \u001b[0m(-0.28319)\n",
            "     | > avg_loss_duration:\u001b[92m 3.51139 \u001b[0m(-0.03028)\n",
            "     | > avg_loss_1:\u001b[91m 28.72111 \u001b[0m(+0.11178)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 638/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:46) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.97214  (2.97214)\n",
            "     | > loss_disc_real_0: 0.24885  (0.24885)\n",
            "     | > loss_disc_real_1: 0.35490  (0.35490)\n",
            "     | > loss_disc_real_2: 0.34146  (0.34146)\n",
            "     | > loss_disc_real_3: 0.28888  (0.28888)\n",
            "     | > loss_disc_real_4: 0.33722  (0.33722)\n",
            "     | > loss_disc_real_5: 0.32736  (0.32736)\n",
            "     | > loss_0: 2.97214  (2.97214)\n",
            "     | > loss_gen: 2.03529  (2.03529)\n",
            "     | > loss_kl: 5.37283  (5.37283)\n",
            "     | > loss_feat: 1.46440  (1.46440)\n",
            "     | > loss_mel: 16.00167  (16.00167)\n",
            "     | > loss_duration: 3.25553  (3.25553)\n",
            "     | > loss_1: 28.12971  (28.12971)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17918 \u001b[0m(-0.00262)\n",
            "     | > avg_loss_disc:\u001b[91m 2.97214 \u001b[0m(+0.23452)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.24885 \u001b[0m(-0.00293)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.35490 \u001b[0m(+0.15984)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.34146 \u001b[0m(+0.15358)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.28888 \u001b[0m(+0.08596)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.33722 \u001b[0m(+0.11948)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.32736 \u001b[0m(+0.09880)\n",
            "     | > avg_loss_0:\u001b[91m 2.97214 \u001b[0m(+0.23452)\n",
            "     | > avg_loss_gen:\u001b[91m 2.03529 \u001b[0m(+0.35268)\n",
            "     | > avg_loss_kl:\u001b[91m 5.37283 \u001b[0m(+0.25938)\n",
            "     | > avg_loss_feat:\u001b[92m 1.46440 \u001b[0m(-0.08622)\n",
            "     | > avg_loss_mel:\u001b[92m 16.00167 \u001b[0m(-0.86137)\n",
            "     | > avg_loss_duration:\u001b[92m 3.25553 \u001b[0m(-0.25586)\n",
            "     | > avg_loss_1:\u001b[92m 28.12971 \u001b[0m(-0.59140)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 639/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:52) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.73714  (2.73714)\n",
            "     | > loss_disc_real_0: 0.14487  (0.14487)\n",
            "     | > loss_disc_real_1: 0.16497  (0.16497)\n",
            "     | > loss_disc_real_2: 0.18746  (0.18746)\n",
            "     | > loss_disc_real_3: 0.23029  (0.23029)\n",
            "     | > loss_disc_real_4: 0.20254  (0.20254)\n",
            "     | > loss_disc_real_5: 0.26264  (0.26264)\n",
            "     | > loss_0: 2.73714  (2.73714)\n",
            "     | > loss_gen: 1.52053  (1.52053)\n",
            "     | > loss_kl: 5.05115  (5.05115)\n",
            "     | > loss_feat: 1.33648  (1.33648)\n",
            "     | > loss_mel: 15.92979  (15.92979)\n",
            "     | > loss_duration: 3.57429  (3.57429)\n",
            "     | > loss_1: 27.41224  (27.41224)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19672 \u001b[0m(+0.01754)\n",
            "     | > avg_loss_disc:\u001b[92m 2.73714 \u001b[0m(-0.23500)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.14487 \u001b[0m(-0.10398)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.16497 \u001b[0m(-0.18993)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.18746 \u001b[0m(-0.15400)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.23029 \u001b[0m(-0.05859)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.20254 \u001b[0m(-0.13468)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.26264 \u001b[0m(-0.06472)\n",
            "     | > avg_loss_0:\u001b[92m 2.73714 \u001b[0m(-0.23500)\n",
            "     | > avg_loss_gen:\u001b[92m 1.52053 \u001b[0m(-0.51476)\n",
            "     | > avg_loss_kl:\u001b[92m 5.05115 \u001b[0m(-0.32167)\n",
            "     | > avg_loss_feat:\u001b[92m 1.33648 \u001b[0m(-0.12792)\n",
            "     | > avg_loss_mel:\u001b[92m 15.92979 \u001b[0m(-0.07188)\n",
            "     | > avg_loss_duration:\u001b[91m 3.57429 \u001b[0m(+0.31876)\n",
            "     | > avg_loss_1:\u001b[92m 27.41224 \u001b[0m(-0.71747)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 640/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:47:58) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.89972  (2.89972)\n",
            "     | > loss_disc_real_0: 0.16689  (0.16689)\n",
            "     | > loss_disc_real_1: 0.29560  (0.29560)\n",
            "     | > loss_disc_real_2: 0.27537  (0.27537)\n",
            "     | > loss_disc_real_3: 0.23106  (0.23106)\n",
            "     | > loss_disc_real_4: 0.25426  (0.25426)\n",
            "     | > loss_disc_real_5: 0.22168  (0.22168)\n",
            "     | > loss_0: 2.89972  (2.89972)\n",
            "     | > loss_gen: 1.66158  (1.66158)\n",
            "     | > loss_kl: 4.87901  (4.87901)\n",
            "     | > loss_feat: 1.28824  (1.28824)\n",
            "     | > loss_mel: 16.55436  (16.55436)\n",
            "     | > loss_duration: 3.71771  (3.71771)\n",
            "     | > loss_1: 28.10091  (28.10091)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18478 \u001b[0m(-0.01194)\n",
            "     | > avg_loss_disc:\u001b[91m 2.89972 \u001b[0m(+0.16258)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.16689 \u001b[0m(+0.02202)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.29560 \u001b[0m(+0.13064)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27537 \u001b[0m(+0.08790)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.23106 \u001b[0m(+0.00077)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.25426 \u001b[0m(+0.05172)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22168 \u001b[0m(-0.04096)\n",
            "     | > avg_loss_0:\u001b[91m 2.89972 \u001b[0m(+0.16258)\n",
            "     | > avg_loss_gen:\u001b[91m 1.66158 \u001b[0m(+0.14106)\n",
            "     | > avg_loss_kl:\u001b[92m 4.87901 \u001b[0m(-0.17214)\n",
            "     | > avg_loss_feat:\u001b[92m 1.28824 \u001b[0m(-0.04824)\n",
            "     | > avg_loss_mel:\u001b[91m 16.55436 \u001b[0m(+0.62457)\n",
            "     | > avg_loss_duration:\u001b[91m 3.71771 \u001b[0m(+0.14342)\n",
            "     | > avg_loss_1:\u001b[91m 28.10091 \u001b[0m(+0.68867)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 641/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:48:04) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 1/3 -- GLOBAL_STEP: 1001925\u001b[0m\n",
            "     | > loss_disc: 2.91505  (2.91505)\n",
            "     | > loss_disc_real_0: 0.16743  (0.16743)\n",
            "     | > loss_disc_real_1: 0.31171  (0.31171)\n",
            "     | > loss_disc_real_2: 0.30269  (0.30269)\n",
            "     | > loss_disc_real_3: 0.22769  (0.22769)\n",
            "     | > loss_disc_real_4: 0.26288  (0.26288)\n",
            "     | > loss_disc_real_5: 0.24199  (0.24199)\n",
            "     | > loss_0: 2.91505  (2.91505)\n",
            "     | > grad_norm_0: 3.72811  (3.72811)\n",
            "     | > loss_gen: 1.85257  (1.85257)\n",
            "     | > loss_kl: 0.70921  (0.70921)\n",
            "     | > loss_feat: 1.24022  (1.24022)\n",
            "     | > loss_mel: 14.49361  (14.49361)\n",
            "     | > loss_duration: 1.45248  (1.45248)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 19.74808  (19.74808)\n",
            "     | > grad_norm_1: 54.33247  (54.33247)\n",
            "     | > current_lr_0: 0.00018 \n",
            "     | > current_lr_1: 0.00018 \n",
            "     | > step_time: 0.56700  (0.56699)\n",
            "     | > loader_time: 0.01980  (0.01978)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.88921  (2.88921)\n",
            "     | > loss_disc_real_0: 0.23571  (0.23571)\n",
            "     | > loss_disc_real_1: 0.27197  (0.27197)\n",
            "     | > loss_disc_real_2: 0.29116  (0.29116)\n",
            "     | > loss_disc_real_3: 0.27962  (0.27962)\n",
            "     | > loss_disc_real_4: 0.29534  (0.29534)\n",
            "     | > loss_disc_real_5: 0.24055  (0.24055)\n",
            "     | > loss_0: 2.88921  (2.88921)\n",
            "     | > loss_gen: 1.81699  (1.81699)\n",
            "     | > loss_kl: 5.31255  (5.31255)\n",
            "     | > loss_feat: 1.54448  (1.54448)\n",
            "     | > loss_mel: 15.44148  (15.44148)\n",
            "     | > loss_duration: 3.40165  (3.40165)\n",
            "     | > loss_1: 27.51716  (27.51716)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.17635 \u001b[0m(-0.00843)\n",
            "     | > avg_loss_disc:\u001b[92m 2.88921 \u001b[0m(-0.01051)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.23571 \u001b[0m(+0.06882)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.27197 \u001b[0m(-0.02363)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.29116 \u001b[0m(+0.01579)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.27962 \u001b[0m(+0.04857)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.29534 \u001b[0m(+0.04108)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.24055 \u001b[0m(+0.01888)\n",
            "     | > avg_loss_0:\u001b[92m 2.88921 \u001b[0m(-0.01051)\n",
            "     | > avg_loss_gen:\u001b[91m 1.81699 \u001b[0m(+0.15541)\n",
            "     | > avg_loss_kl:\u001b[91m 5.31255 \u001b[0m(+0.43354)\n",
            "     | > avg_loss_feat:\u001b[91m 1.54448 \u001b[0m(+0.25624)\n",
            "     | > avg_loss_mel:\u001b[92m 15.44148 \u001b[0m(-1.11288)\n",
            "     | > avg_loss_duration:\u001b[92m 3.40165 \u001b[0m(-0.31606)\n",
            "     | > avg_loss_1:\u001b[92m 27.51716 \u001b[0m(-0.58374)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 642/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:48:10) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.83527  (2.83527)\n",
            "     | > loss_disc_real_0: 0.15007  (0.15007)\n",
            "     | > loss_disc_real_1: 0.22469  (0.22469)\n",
            "     | > loss_disc_real_2: 0.21487  (0.21487)\n",
            "     | > loss_disc_real_3: 0.25048  (0.25048)\n",
            "     | > loss_disc_real_4: 0.22418  (0.22418)\n",
            "     | > loss_disc_real_5: 0.26357  (0.26357)\n",
            "     | > loss_0: 2.83527  (2.83527)\n",
            "     | > loss_gen: 1.52173  (1.52173)\n",
            "     | > loss_kl: 5.02669  (5.02669)\n",
            "     | > loss_feat: 0.91413  (0.91413)\n",
            "     | > loss_mel: 13.16067  (13.16067)\n",
            "     | > loss_duration: 3.42283  (3.42283)\n",
            "     | > loss_1: 24.04604  (24.04604)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.17758 \u001b[0m(+0.00123)\n",
            "     | > avg_loss_disc:\u001b[92m 2.83527 \u001b[0m(-0.05394)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.15007 \u001b[0m(-0.08563)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.22469 \u001b[0m(-0.04728)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.21487 \u001b[0m(-0.07628)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.25048 \u001b[0m(-0.02914)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.22418 \u001b[0m(-0.07116)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.26357 \u001b[0m(+0.02302)\n",
            "     | > avg_loss_0:\u001b[92m 2.83527 \u001b[0m(-0.05394)\n",
            "     | > avg_loss_gen:\u001b[92m 1.52173 \u001b[0m(-0.29527)\n",
            "     | > avg_loss_kl:\u001b[92m 5.02669 \u001b[0m(-0.28587)\n",
            "     | > avg_loss_feat:\u001b[92m 0.91413 \u001b[0m(-0.63036)\n",
            "     | > avg_loss_mel:\u001b[92m 13.16067 \u001b[0m(-2.28081)\n",
            "     | > avg_loss_duration:\u001b[91m 3.42283 \u001b[0m(+0.02117)\n",
            "     | > avg_loss_1:\u001b[92m 24.04604 \u001b[0m(-3.47113)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 643/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:48:17) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.78838  (2.78838)\n",
            "     | > loss_disc_real_0: 0.25451  (0.25451)\n",
            "     | > loss_disc_real_1: 0.26861  (0.26861)\n",
            "     | > loss_disc_real_2: 0.23927  (0.23927)\n",
            "     | > loss_disc_real_3: 0.18519  (0.18519)\n",
            "     | > loss_disc_real_4: 0.24660  (0.24660)\n",
            "     | > loss_disc_real_5: 0.22770  (0.22770)\n",
            "     | > loss_0: 2.78838  (2.78838)\n",
            "     | > loss_gen: 1.69807  (1.69807)\n",
            "     | > loss_kl: 4.88241  (4.88241)\n",
            "     | > loss_feat: 1.37255  (1.37255)\n",
            "     | > loss_mel: 15.74370  (15.74370)\n",
            "     | > loss_duration: 3.66918  (3.66918)\n",
            "     | > loss_1: 27.36591  (27.36591)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.18713 \u001b[0m(+0.00955)\n",
            "     | > avg_loss_disc:\u001b[92m 2.78838 \u001b[0m(-0.04689)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.25451 \u001b[0m(+0.10443)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.26861 \u001b[0m(+0.04391)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.23927 \u001b[0m(+0.02440)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.18519 \u001b[0m(-0.06529)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.24660 \u001b[0m(+0.02242)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.22770 \u001b[0m(-0.03586)\n",
            "     | > avg_loss_0:\u001b[92m 2.78838 \u001b[0m(-0.04689)\n",
            "     | > avg_loss_gen:\u001b[91m 1.69807 \u001b[0m(+0.17634)\n",
            "     | > avg_loss_kl:\u001b[92m 4.88241 \u001b[0m(-0.14428)\n",
            "     | > avg_loss_feat:\u001b[91m 1.37255 \u001b[0m(+0.45843)\n",
            "     | > avg_loss_mel:\u001b[91m 15.74370 \u001b[0m(+2.58304)\n",
            "     | > avg_loss_duration:\u001b[91m 3.66918 \u001b[0m(+0.24635)\n",
            "     | > avg_loss_1:\u001b[91m 27.36591 \u001b[0m(+3.31988)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 644/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:48:23) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.88740  (2.88740)\n",
            "     | > loss_disc_real_0: 0.20694  (0.20694)\n",
            "     | > loss_disc_real_1: 0.20932  (0.20932)\n",
            "     | > loss_disc_real_2: 0.22842  (0.22842)\n",
            "     | > loss_disc_real_3: 0.22894  (0.22894)\n",
            "     | > loss_disc_real_4: 0.22658  (0.22658)\n",
            "     | > loss_disc_real_5: 0.20192  (0.20192)\n",
            "     | > loss_0: 2.88740  (2.88740)\n",
            "     | > loss_gen: 1.45614  (1.45614)\n",
            "     | > loss_kl: 4.80021  (4.80021)\n",
            "     | > loss_feat: 1.18100  (1.18100)\n",
            "     | > loss_mel: 17.25613  (17.25613)\n",
            "     | > loss_duration: 3.56458  (3.56458)\n",
            "     | > loss_1: 28.25806  (28.25806)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.18440 \u001b[0m(-0.00273)\n",
            "     | > avg_loss_disc:\u001b[91m 2.88740 \u001b[0m(+0.09901)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.20694 \u001b[0m(-0.04757)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20932 \u001b[0m(-0.05929)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.22842 \u001b[0m(-0.01085)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.22894 \u001b[0m(+0.04376)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.22658 \u001b[0m(-0.02002)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.20192 \u001b[0m(-0.02578)\n",
            "     | > avg_loss_0:\u001b[91m 2.88740 \u001b[0m(+0.09901)\n",
            "     | > avg_loss_gen:\u001b[92m 1.45614 \u001b[0m(-0.24193)\n",
            "     | > avg_loss_kl:\u001b[92m 4.80021 \u001b[0m(-0.08220)\n",
            "     | > avg_loss_feat:\u001b[92m 1.18100 \u001b[0m(-0.19155)\n",
            "     | > avg_loss_mel:\u001b[91m 17.25613 \u001b[0m(+1.51243)\n",
            "     | > avg_loss_duration:\u001b[92m 3.56458 \u001b[0m(-0.10460)\n",
            "     | > avg_loss_1:\u001b[91m 28.25806 \u001b[0m(+0.89215)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 645/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:48:29) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.86482  (2.86482)\n",
            "     | > loss_disc_real_0: 0.31843  (0.31843)\n",
            "     | > loss_disc_real_1: 0.22397  (0.22397)\n",
            "     | > loss_disc_real_2: 0.21833  (0.21833)\n",
            "     | > loss_disc_real_3: 0.23507  (0.23507)\n",
            "     | > loss_disc_real_4: 0.24296  (0.24296)\n",
            "     | > loss_disc_real_5: 0.21637  (0.21637)\n",
            "     | > loss_0: 2.86482  (2.86482)\n",
            "     | > loss_gen: 1.69606  (1.69606)\n",
            "     | > loss_kl: 4.78363  (4.78363)\n",
            "     | > loss_feat: 1.06466  (1.06466)\n",
            "     | > loss_mel: 14.63274  (14.63274)\n",
            "     | > loss_duration: 3.52298  (3.52298)\n",
            "     | > loss_1: 25.70007  (25.70007)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.19700 \u001b[0m(+0.01260)\n",
            "     | > avg_loss_disc:\u001b[92m 2.86482 \u001b[0m(-0.02257)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.31843 \u001b[0m(+0.11149)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.22397 \u001b[0m(+0.01465)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.21833 \u001b[0m(-0.01009)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.23507 \u001b[0m(+0.00612)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.24296 \u001b[0m(+0.01638)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.21637 \u001b[0m(+0.01445)\n",
            "     | > avg_loss_0:\u001b[92m 2.86482 \u001b[0m(-0.02257)\n",
            "     | > avg_loss_gen:\u001b[91m 1.69606 \u001b[0m(+0.23991)\n",
            "     | > avg_loss_kl:\u001b[92m 4.78363 \u001b[0m(-0.01657)\n",
            "     | > avg_loss_feat:\u001b[92m 1.06466 \u001b[0m(-0.11633)\n",
            "     | > avg_loss_mel:\u001b[92m 14.63274 \u001b[0m(-2.62339)\n",
            "     | > avg_loss_duration:\u001b[92m 3.52298 \u001b[0m(-0.04160)\n",
            "     | > avg_loss_1:\u001b[92m 25.70007 \u001b[0m(-2.55799)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 646/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/VoiceCloning/output/vits_ljspeech-August-05-2022_12+35AM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 5\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 135\n",
            " | > Min text length: 65\n",
            " | > Avg text length: 105.4\n",
            " | \n",
            " | > Max audio length: 202774.0\n",
            " | > Min audio length: 104470.0\n",
            " | > Avg audio length: 172873.2\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 4.\n",
            "\n",
            "\u001b[1m > TRAINING (2022-08-05 01:48:36) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: gruut\n",
            "| > Number of instances : 2\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 112\n",
            " | > Min text length: 99\n",
            " | > Avg text length: 105.5\n",
            " | \n",
            " | > Max audio length: 188438.0\n",
            " | > Min audio length: 187414.0\n",
            " | > Avg audio length: 187926.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 2.94445  (2.94445)\n",
            "     | > loss_disc_real_0: 0.18635  (0.18635)\n",
            "     | > loss_disc_real_1: 0.32081  (0.32081)\n",
            "     | > loss_disc_real_2: 0.29530  (0.29530)\n",
            "     | > loss_disc_real_3: 0.29000  (0.29000)\n",
            "     | > loss_disc_real_4: 0.29259  (0.29259)\n",
            "     | > loss_disc_real_5: 0.31089  (0.31089)\n",
            "     | > loss_0: 2.94445  (2.94445)\n",
            "     | > loss_gen: 1.80283  (1.80283)\n",
            "     | > loss_kl: 5.04414  (5.04414)\n",
            "     | > loss_feat: 1.09629  (1.09629)\n",
            "     | > loss_mel: 16.00604  (16.00604)\n",
            "     | > loss_duration: 3.66434  (3.66434)\n",
            "     | > loss_1: 27.61364  (27.61364)\n",
            "\n",
            " | > Synthesizing test sentences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tts --text \"This is a program about Applied Health Informatics.\" \\\n",
        "    --model_path /content/drive/MyDrive/VoiceCloning/log/INSERT_MODEL.tar \\\n",
        "    --config_path /content/drive/MyDrive/VoiceCloning/log/CONFIG.json \\\n",
        "    --out_path /content/drive/MyDrive/VoiceCloning/output/output.wav\n"
      ],
      "metadata": {
        "id": "k2fO-F8hXPXw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}